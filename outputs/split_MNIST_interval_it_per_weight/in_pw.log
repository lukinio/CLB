split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.289, Loss 0.023
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 99.905, time 0.48
Epoch:1
LR: 0.001
 * Train Acc 99.929, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.44
Epoch:2
LR: 0.001
 * Train Acc 99.929, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.49
Epoch:3
LR: 0.001
 * Train Acc 99.937, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.43
Epoch:4
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.45
Epoch:5
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.48
Epoch:6
LR: 0.001
 * Train Acc 99.937, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.858, time 0.48
Epoch:7
LR: 0.001
 * Train Acc 99.968, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.47
Epoch:8
LR: 0.001
 * Train Acc 99.968, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.47
Epoch:9
LR: 0.001
 * Train Acc 99.976, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.42
Epoch:10
LR: 0.001
 * Train Acc 99.937, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.52
Epoch:11
LR: 0.001
 * Train Acc 99.961, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.47
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1285.1016845703125 -mean: 0.0031374553218483925 - std: 0.00039997624116949737
 * min 0.0015350290341302752, max: 0.003730876138433814
sum: 661.369873046875 -mean: 0.004133561626076698 - std: 0.000425679114414379
 * min 0.002423992846161127, max: 0.005175560712814331
sum: 6.267640590667725 - mean: 0.00783455092459917 - std: 0.00031897745793685317
 * min 0.007016151677817106, max: 0.008759498596191406
sum eps on layers: tensor([3.2128, 1.6534, 3.1338], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.47
 * Lower 1 Val Acc 99.905, time 0.48
 * Upper 1 Val Acc 99.905, time 0.53
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 93.068, Loss 0.217
 * , robust loss: 0.094 robust error: 0.02247191
 *  Val Acc 97.160, time 0.48
Epoch:1
LR: 0.001
 * Train Acc 96.559, Loss 0.083
 * , robust loss: 0.014 robust error: 0.00000000
 *  Val Acc 98.041, time 0.47
Epoch:2
LR: 0.001
 * Train Acc 97.221, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.698, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 96.890, Loss 0.053
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.090, time 0.45
Epoch:4
LR: 0.001
 * Train Acc 97.063, Loss 0.050
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.482, time 0.52
Epoch:5
LR: 0.001
 * Train Acc 97.138, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.335, time 0.54
Epoch:6
LR: 0.001
 * Train Acc 97.212, Loss 0.048
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.041, time 0.52
Epoch:7
LR: 0.001
 * Train Acc 97.121, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.747, time 0.48
Epoch:8
LR: 0.001
 * Train Acc 97.188, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.915, time 0.51
Epoch:9
LR: 0.001
 * Train Acc 97.154, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.600, time 0.45
Epoch:10
LR: 0.001
 * Train Acc 97.055, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.041, time 0.44
Epoch:11
LR: 0.001
 * Train Acc 97.047, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.747, time 0.44
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1085.2080078125 -mean: 0.002649433445185423 - std: 0.0008612819947302341
 * min 0.0005462407716549933, max: 0.0038673682138323784
sum: 153.17535400390625 -mean: 0.0009573459392413497 - std: 0.0002623814216349274
 * min 0.0002777713816612959, max: 0.0014814534224569798
sum: 1.8080832958221436 - mean: 0.0022601040545850992 - std: 0.00015528527728747576
 * min 0.0017943242564797401, max: 0.0028628779109567404
sum eps on layers: tensor([2.7130, 0.3829, 0.9040], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.44
 * Lower 1 Val Acc 99.905, time 0.51
 * Upper 1 Val Acc 99.905, time 0.46
validation split name: 2
 *  Val Acc 97.747, time 0.44
 * Lower 1 Val Acc 97.649, time 0.45
 * Upper 1 Val Acc 97.649, time 0.48
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 89.621, Loss 0.318
 * , robust loss: 0.036 robust error: 0.00000000
 *  Val Acc 95.304, time 0.55
Epoch:1
LR: 0.001
 * Train Acc 96.049, Loss 0.109
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 96.905, time 0.49
Epoch:2
LR: 0.001
 * Train Acc 96.946, Loss 0.083
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.279, time 0.45
Epoch:3
LR: 0.001
 * Train Acc 97.354, Loss 0.071
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.652, time 0.48
Epoch:4
LR: 0.001
 * Train Acc 97.692, Loss 0.063
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.919, time 0.53
Epoch:5
LR: 0.001
 * Train Acc 97.914, Loss 0.059
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.705, time 0.47
Epoch:6
LR: 0.001
 * Train Acc 97.780, Loss 0.058
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.759, time 0.43
Epoch:7
LR: 0.001
 * Train Acc 97.860, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.812, time 0.44
Epoch:8
LR: 0.001
 * Train Acc 97.798, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.759, time 0.42
Epoch:9
LR: 0.001
 * Train Acc 97.896, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.919, time 0.47
Epoch:10
LR: 0.001
 * Train Acc 97.860, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.118, time 0.45
Epoch:11
LR: 0.001
 * Train Acc 97.851, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.812, time 0.45
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1294.407470703125 -mean: 0.0031601744703948498 - std: 0.001183551037684083
 * min 0.00046108197420835495, max: 0.004868228919804096
sum: 98.78242492675781 -mean: 0.0006173901492729783 - std: 0.00018916951376013458
 * min 0.00014116482634563, max: 0.0009944799821823835
sum: 1.0340501070022583 - mean: 0.0012925625778734684 - std: 0.00011435337364673615
 * min 0.0010276478715240955, max: 0.0016364878974854946
sum eps on layers: tensor([3.2360, 0.2470, 0.5170], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.46
 * Lower 1 Val Acc 99.905, time 0.43
 * Upper 1 Val Acc 99.905, time 0.45
validation split name: 2
 *  Val Acc 96.719, time 0.46
 * Lower 1 Val Acc 97.405, time 0.39
 * Upper 1 Val Acc 97.405, time 0.41
validation split name: 3
 *  Val Acc 97.812, time 0.40
 * Lower 1 Val Acc 96.051, time 0.47
 * Upper 1 Val Acc 96.051, time 0.45
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 92.424, Loss 0.348
 * , robust loss: 0.083 robust error: 0.00000000
 *  Val Acc 97.482, time 0.43
Epoch:1
LR: 0.001
 * Train Acc 98.785, Loss 0.095
 * , robust loss: 0.011 robust error: 0.00000000
 *  Val Acc 98.691, time 0.45
Epoch:2
LR: 0.001
 * Train Acc 99.114, Loss 0.053
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 98.792, time 0.49
Epoch:3
LR: 0.001
 * Train Acc 99.294, Loss 0.039
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.043, time 0.47
Epoch:4
LR: 0.001
 * Train Acc 99.319, Loss 0.032
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.396, time 0.48
Epoch:5
LR: 0.001
 * Train Acc 99.425, Loss 0.028
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.547, time 0.44
Epoch:6
LR: 0.001
 * Train Acc 99.450, Loss 0.025
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.547, time 0.45
Epoch:7
LR: 0.001
 * Train Acc 99.524, Loss 0.022
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.496, time 0.53
Epoch:8
LR: 0.001
 * Train Acc 99.549, Loss 0.019
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.993, time 0.49
Epoch:9
LR: 0.001
 * Train Acc 99.549, Loss 0.018
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.446, time 0.40
Epoch:10
LR: 0.001
 * Train Acc 99.458, Loss 0.018
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.597, time 0.44
Epoch:11
LR: 0.001
 * Train Acc 99.475, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.144, time 0.45
after batch eps: 1.500000000000037, kappa: 0.5
sum: 538.1090087890625 -mean: 0.0013137427158653736 - std: 0.000578568724449724
 * min 0.00011441329843364656, max: 0.002200186951085925
sum: 20.889888763427734 -mean: 0.00013056180614512414 - std: 4.3503550841705874e-05
 * min 2.5691682822071016e-05, max: 0.00021675945026800036
sum: 0.20500542223453522 - mean: 0.0002562567824497819 - std: 2.463661257934291e-05
 * min 0.00020047053112648427, max: 0.00033239895128645003
sum eps on layers: tensor([1.3453, 0.0522, 0.1025], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.41
 * Lower 1 Val Acc 99.905, time 0.52
 * Upper 1 Val Acc 99.905, time 0.39
validation split name: 2
 *  Val Acc 96.768, time 0.48
 * Lower 1 Val Acc 97.062, time 0.46
 * Upper 1 Val Acc 97.062, time 0.46
validation split name: 3
 *  Val Acc 97.652, time 0.44
 * Lower 1 Val Acc 98.132, time 0.45
 * Upper 1 Val Acc 98.132, time 0.43
validation split name: 4
 *  Val Acc 99.144, time 0.52
 * Lower 1 Val Acc 99.043, time 0.46
 * Upper 1 Val Acc 99.043, time 0.37
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 85.042, Loss 0.408
 * , robust loss: 0.199 robust error: 0.04000000
 *  Val Acc 90.822, time 0.77
Epoch:1
LR: 0.001
 * Train Acc 92.322, Loss 0.197
 * , robust loss: 0.057 robust error: 0.00000000
 *  Val Acc 93.545, time 0.43
Epoch:2
LR: 0.001
 * Train Acc 93.873, Loss 0.129
 * , robust loss: 0.017 robust error: 0.01000000
 *  Val Acc 94.755, time 0.43
Epoch:3
LR: 0.001
 * Train Acc 94.517, Loss 0.104
 * , robust loss: 0.004 robust error: 0.00000000
 *  Val Acc 94.705, time 0.43
Epoch:4
LR: 0.001
 * Train Acc 94.754, Loss 0.093
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 94.755, time 0.46
Epoch:5
LR: 0.001
 * Train Acc 95.042, Loss 0.086
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.008, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 95.229, Loss 0.081
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 94.806, time 0.42
Epoch:7
LR: 0.001
 * Train Acc 95.508, Loss 0.078
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.512, time 0.38
Epoch:8
LR: 0.001
 * Train Acc 95.517, Loss 0.075
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.764, time 0.46
Epoch:9
LR: 0.001
 * Train Acc 95.644, Loss 0.073
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.663, time 0.44
Epoch:10
LR: 0.001
 * Train Acc 95.898, Loss 0.071
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.067, time 0.44
Epoch:11
LR: 0.001
 * Train Acc 95.839, Loss 0.069
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.814, time 0.46
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 384.2532653808594 -mean: 0.0009381183190271258 - std: 0.000492795486934483
 * min 3.315971480333246e-05, max: 0.001711147022433579
sum: 5.48457145690918 -mean: 3.427857154747471e-05 - std: 1.233295461133821e-05
 * min 5.66865401196992e-06, max: 5.916776353842579e-05
sum: 0.051310695707798004 - mean: 6.413836672436446e-05 - std: 7.566397471236996e-06
 * min 4.776075002155267e-05, max: 8.785584941506386e-05
sum eps on layers: tensor([0.9606, 0.0137, 0.0257], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.46
 * Lower 1 Val Acc 99.905, time 0.50
 * Upper 1 Val Acc 99.905, time 0.50
validation split name: 2
 *  Val Acc 96.621, time 0.45
 * Lower 1 Val Acc 96.817, time 0.42
 * Upper 1 Val Acc 96.817, time 0.47
validation split name: 3
 *  Val Acc 97.705, time 0.47
 * Lower 1 Val Acc 98.346, time 0.45
 * Upper 1 Val Acc 98.346, time 0.44
validation split name: 4
 *  Val Acc 97.281, time 0.42
 * Lower 1 Val Acc 96.828, time 0.49
 * Upper 1 Val Acc 96.828, time 0.44
validation split name: 5
 *  Val Acc 95.814, time 0.38
 * Lower 1 Val Acc 95.663, time 0.45
 * Upper 1 Val Acc 95.663, time 0.53
Task 1 average acc: 99.90543735224587
Task 2 average acc: 98.82637195721989
Task 3 average acc: 98.14550229242629
Task 4 average acc: 98.36735028781973
Task 5 average acc: 97.46544589156443
===Summary of experiment repeats: 1 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589  0.          0.          0.          0.          0.
  0.          0.          0.          0.        ]
mean: 9.746544589156443 std: 29.239633767469332
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.305, Loss 0.022
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.51
Epoch:1
LR: 0.001
 * Train Acc 99.905, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.53
Epoch:2
LR: 0.001
 * Train Acc 99.961, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.52
Epoch:3
LR: 0.001
 * Train Acc 99.921, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.56
Epoch:4
LR: 0.001
 * Train Acc 99.953, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.49
Epoch:5
LR: 0.001
 * Train Acc 99.929, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.46
Epoch:6
LR: 0.001
 * Train Acc 99.976, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.43
Epoch:7
LR: 0.001
 * Train Acc 99.992, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.45
Epoch:8
LR: 0.001
 * Train Acc 99.929, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
Epoch:9
LR: 0.001
 * Train Acc 99.976, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.49
Epoch:10
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.44
Epoch:11
LR: 0.001
 * Train Acc 99.992, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1382.7568359375 -mean: 0.003375871106982231 - std: 0.0004265169845893979
 * min 0.0017153896624222398, max: 0.003950256854295731
sum: 648.4921875 -mean: 0.004053076263517141 - std: 0.0004063887463416904
 * min 0.002447871956974268, max: 0.0051108356565237045
sum: 5.84375524520874 - mean: 0.007304694037884474 - std: 0.00027362233959138393
 * min 0.006246402394026518, max: 0.008589311502873898
sum eps on layers: tensor([3.4569, 1.6212, 2.9219], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.42
 * Lower 1 Val Acc 99.953, time 0.45
 * Upper 1 Val Acc 99.953, time 0.48
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.110, Loss 0.173
 * , robust loss: 0.078 robust error: 0.01123596
 *  Val Acc 96.817, time 0.42
Epoch:1
LR: 0.001
 * Train Acc 96.881, Loss 0.069
 * , robust loss: 0.003 robust error: 0.00000000
 *  Val Acc 97.013, time 0.41
Epoch:2
LR: 0.001
 * Train Acc 97.146, Loss 0.050
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.405, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 97.328, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.600, time 0.44
Epoch:4
LR: 0.001
 * Train Acc 97.394, Loss 0.044
 * , robust loss: 0.003 robust error: 0.00000000
 *  Val Acc 98.188, time 0.43
Epoch:5
LR: 0.001
 * Train Acc 97.436, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.894, time 0.42
Epoch:6
LR: 0.001
 * Train Acc 97.336, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.139, time 0.45
Epoch:7
LR: 0.001
 * Train Acc 97.386, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.258, time 0.46
Epoch:8
LR: 0.001
 * Train Acc 97.279, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.992, time 0.44
Epoch:9
LR: 0.001
 * Train Acc 97.527, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.747, time 0.55
Epoch:10
LR: 0.001
 * Train Acc 97.370, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.572, time 0.48
Epoch:11
LR: 0.001
 * Train Acc 97.295, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.747, time 0.52
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1158.044921875 -mean: 0.0028272580821067095 - std: 0.0009404134470969439
 * min 0.000607468537054956, max: 0.00409929733723402
sum: 154.37448120117188 -mean: 0.0009648404666222632 - std: 0.00024849234614521265
 * min 0.00031063921051099896, max: 0.0015270893927663565
sum: 1.437902808189392 - mean: 0.0017973784124478698 - std: 0.00010189337626798078
 * min 0.0015109345549717546, max: 0.0021415038499981165
sum eps on layers: tensor([2.8951, 0.3859, 0.7190], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.45
 * Lower 1 Val Acc 99.905, time 0.46
 * Upper 1 Val Acc 99.905, time 0.46
validation split name: 2
 *  Val Acc 97.747, time 0.46
 * Lower 1 Val Acc 97.992, time 0.50
 * Upper 1 Val Acc 97.992, time 0.48
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 90.722, Loss 0.308
 * , robust loss: 0.037 robust error: 0.00000000
 *  Val Acc 96.852, time 0.52
Epoch:1
LR: 0.001
 * Train Acc 97.692, Loss 0.084
 * , robust loss: 0.002 robust error: 0.00000000
 *  Val Acc 97.759, time 0.56
Epoch:2
LR: 0.001
 * Train Acc 98.189, Loss 0.061
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.026, time 0.46
Epoch:3
LR: 0.001
 * Train Acc 98.437, Loss 0.052
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.239, time 0.38
Epoch:4
LR: 0.001
 * Train Acc 98.579, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.453, time 0.44
Epoch:5
LR: 0.001
 * Train Acc 98.606, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.346, time 0.41
Epoch:6
LR: 0.001
 * Train Acc 98.544, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.079, time 0.43
Epoch:7
LR: 0.001
 * Train Acc 98.446, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.239, time 0.45
Epoch:8
LR: 0.001
 * Train Acc 98.437, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.346, time 0.43
Epoch:9
LR: 0.001
 * Train Acc 98.464, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.41
Epoch:10
LR: 0.001
 * Train Acc 98.224, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.132, time 0.42
Epoch:11
LR: 0.001
 * Train Acc 98.402, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.239, time 0.50
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1332.240234375 -mean: 0.003252539550885558 - std: 0.0012499862350523472
 * min 0.0005109310150146484, max: 0.004994382616132498
sum: 101.28705596923828 -mean: 0.0006330441101454198 - std: 0.00018182968779001385
 * min 0.00018171450938098133, max: 0.0010292432270944118
sum: 0.8323631286621094 - mean: 0.0010404539061710238 - std: 9.34343843255192e-05
 * min 0.0008532623760402203, max: 0.001276690629310906
sum eps on layers: tensor([3.3306, 0.2532, 0.4162], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.56
 * Lower 1 Val Acc 99.905, time 0.48
 * Upper 1 Val Acc 99.905, time 0.48
validation split name: 2
 *  Val Acc 97.698, time 0.37
 * Lower 1 Val Acc 97.747, time 0.47
 * Upper 1 Val Acc 97.747, time 0.44
validation split name: 3
 *  Val Acc 98.239, time 0.51
 * Lower 1 Val Acc 90.128, time 0.44
 * Upper 1 Val Acc 90.128, time 0.44
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 95.551, Loss 0.214
 * , robust loss: 0.052 robust error: 0.00000000
 *  Val Acc 98.943, time 0.42
Epoch:1
LR: 0.001
 * Train Acc 99.311, Loss 0.043
 * , robust loss: 0.007 robust error: 0.00000000
 *  Val Acc 99.345, time 0.52
Epoch:2
LR: 0.001
 * Train Acc 99.483, Loss 0.025
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 99.245, time 0.46
Epoch:3
LR: 0.001
 * Train Acc 99.557, Loss 0.019
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.446, time 0.44
Epoch:4
LR: 0.001
 * Train Acc 99.639, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.446, time 0.40
Epoch:5
LR: 0.001
 * Train Acc 99.631, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.396, time 0.43
Epoch:6
LR: 0.001
 * Train Acc 99.631, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.396, time 0.50
Epoch:7
LR: 0.001
 * Train Acc 99.639, Loss 0.012
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.496, time 0.44
Epoch:8
LR: 0.001
 * Train Acc 99.647, Loss 0.012
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.496, time 0.41
Epoch:9
LR: 0.001
 * Train Acc 99.663, Loss 0.011
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.547, time 0.42
Epoch:10
LR: 0.001
 * Train Acc 99.581, Loss 0.011
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.345, time 0.47
Epoch:11
LR: 0.001
 * Train Acc 99.631, Loss 0.011
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.345, time 0.46
after batch eps: 1.500000000000037, kappa: 0.5
sum: 536.6701049804688 -mean: 0.001310229767113924 - std: 0.0005717983585782349
 * min 0.0001491998409619555, max: 0.0021256597246974707
sum: 24.845979690551758 -mean: 0.00015528737276326865 - std: 4.754440305987373e-05
 * min 3.873002060572617e-05, max: 0.00025914859725162387
sum: 0.19241951406002045 - mean: 0.00024052438675425947 - std: 2.067197965516243e-05
 * min 0.00019191823957953602, max: 0.0003066078061237931
sum eps on layers: tensor([1.3417, 0.0621, 0.0962], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.42
 * Lower 1 Val Acc 99.953, time 0.46
 * Upper 1 Val Acc 99.953, time 0.50
validation split name: 2
 *  Val Acc 98.384, time 0.42
 * Lower 1 Val Acc 98.384, time 0.47
 * Upper 1 Val Acc 98.384, time 0.49
validation split name: 3
 *  Val Acc 93.757, time 0.54
 * Lower 1 Val Acc 96.905, time 0.43
 * Upper 1 Val Acc 96.905, time 0.44
validation split name: 4
 *  Val Acc 99.345, time 0.44
 * Lower 1 Val Acc 99.144, time 0.39
 * Upper 1 Val Acc 99.144, time 0.42
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 85.898, Loss 0.379
 * , robust loss: 0.145 robust error: 0.02000000
 *  Val Acc 91.024, time 0.44
Epoch:1
LR: 0.001
 * Train Acc 93.568, Loss 0.163
 * , robust loss: 0.033 robust error: 0.00000000
 *  Val Acc 94.302, time 0.46
Epoch:2
LR: 0.001
 * Train Acc 94.992, Loss 0.106
 * , robust loss: 0.007 robust error: 0.00000000
 *  Val Acc 94.655, time 0.83
Epoch:3
LR: 0.001
 * Train Acc 95.356, Loss 0.087
 * , robust loss: 0.002 robust error: 0.00000000
 *  Val Acc 95.058, time 0.40
Epoch:4
LR: 0.001
 * Train Acc 95.703, Loss 0.079
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.361, time 0.48
Epoch:5
LR: 0.001
 * Train Acc 95.788, Loss 0.073
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.714, time 0.43
Epoch:6
LR: 0.001
 * Train Acc 96.008, Loss 0.070
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.915, time 0.42
Epoch:7
LR: 0.001
 * Train Acc 96.398, Loss 0.066
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.268, time 0.47
Epoch:8
LR: 0.001
 * Train Acc 96.390, Loss 0.064
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.268, time 0.49
Epoch:9
LR: 0.001
 * Train Acc 96.483, Loss 0.062
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.117, time 0.44
Epoch:10
LR: 0.001
 * Train Acc 96.508, Loss 0.060
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.167, time 0.43
Epoch:11
LR: 0.001
 * Train Acc 96.712, Loss 0.059
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.167, time 0.44
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 385.3681335449219 -mean: 0.0009408401674591005 - std: 0.0005037024384364486
 * min 4.1798106394708157e-05, max: 0.0016748521011322737
sum: 5.973363876342773 -mean: 3.73335242329631e-05 - std: 1.2498720025178045e-05
 * min 7.559040113847004e-06, max: 6.551246769959107e-05
sum: 0.04329264163970947 - mean: 5.411580059444532e-05 - std: 5.420967227109941e-06
 * min 4.184049612376839e-05, max: 7.135502528399229e-05
sum eps on layers: tensor([0.9634, 0.0149, 0.0216], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.46
 * Lower 1 Val Acc 99.953, time 0.43
 * Upper 1 Val Acc 99.953, time 0.39
validation split name: 2
 *  Val Acc 98.286, time 0.42
 * Lower 1 Val Acc 98.139, time 0.41
 * Upper 1 Val Acc 98.139, time 0.41
validation split name: 3
 *  Val Acc 92.903, time 0.42
 * Lower 1 Val Acc 96.158, time 0.53
 * Upper 1 Val Acc 96.158, time 0.41
validation split name: 4
 *  Val Acc 99.396, time 0.46
 * Lower 1 Val Acc 99.345, time 0.40
 * Upper 1 Val Acc 99.345, time 0.41
validation split name: 5
 *  Val Acc 96.167, time 0.47
 * Lower 1 Val Acc 95.663, time 0.42
 * Upper 1 Val Acc 95.663, time 0.52
Task 1 average acc: 99.95271867612293
Task 2 average acc: 98.82637195721989
Task 3 average acc: 98.61427771680324
Task 4 average acc: 97.85968603551933
Task 5 average acc: 97.34095756508378
===Summary of experiment repeats: 2 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757  0.          0.          0.          0.
  0.          0.          0.          0.        ]
mean: 19.48064034566482 std: 38.96129063539538
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.432, Loss 0.020
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.858, time 0.46
Epoch:1
LR: 0.001
 * Train Acc 99.882, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
Epoch:2
LR: 0.001
 * Train Acc 99.921, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
Epoch:3
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.46
Epoch:4
LR: 0.001
 * Train Acc 99.937, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.47
Epoch:5
LR: 0.001
 * Train Acc 99.984, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.46
Epoch:6
LR: 0.001
 * Train Acc 99.976, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.43
Epoch:7
LR: 0.001
 * Train Acc 99.968, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.47
Epoch:8
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.51
Epoch:9
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.48
Epoch:10
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.48
Epoch:11
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.46
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1256.86865234375 -mean: 0.0030685269739478827 - std: 0.0003468432405497879
 * min 0.0017469815211370587, max: 0.003525093663483858
sum: 703.9620361328125 -mean: 0.004399762488901615 - std: 0.00036988413194194436
 * min 0.0029162929859012365, max: 0.005333158653229475
sum: 6.195845603942871 - mean: 0.007744806818664074 - std: 0.0002977623662445694
 * min 0.0068664890713989735, max: 0.008758793585002422
sum eps on layers: tensor([3.1422, 1.7599, 3.0979], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.41
 * Lower 1 Val Acc 99.905, time 0.50
 * Upper 1 Val Acc 99.905, time 0.47
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.052, Loss 0.179
 * , robust loss: 0.068 robust error: 0.02247191
 *  Val Acc 97.209, time 0.52
Epoch:1
LR: 0.001
 * Train Acc 96.840, Loss 0.068
 * , robust loss: 0.006 robust error: 0.00000000
 *  Val Acc 97.845, time 0.39
Epoch:2
LR: 0.001
 * Train Acc 97.361, Loss 0.047
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 97.845, time 0.46
Epoch:3
LR: 0.001
 * Train Acc 97.154, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.041, time 0.42
Epoch:4
LR: 0.001
 * Train Acc 97.527, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.433, time 0.44
Epoch:5
LR: 0.001
 * Train Acc 97.403, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.943, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 97.336, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.796, time 0.43
Epoch:7
LR: 0.001
 * Train Acc 97.461, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.356, time 0.44
Epoch:8
LR: 0.001
 * Train Acc 97.568, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.894, time 0.43
Epoch:9
LR: 0.001
 * Train Acc 97.245, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.209, time 0.43
Epoch:10
LR: 0.001
 * Train Acc 97.353, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.335, time 0.45
Epoch:11
LR: 0.001
 * Train Acc 97.394, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.139, time 0.48
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1116.22021484375 -mean: 0.002725146943703294 - std: 0.0008829483413137496
 * min 0.0006046397029422224, max: 0.003942093346267939
sum: 157.0370635986328 -mean: 0.0009814816294237971 - std: 0.00024662402574904263
 * min 0.0003130463883280754, max: 0.0014698717277497053
sum: 1.6337138414382935 - mean: 0.0020421422086656094 - std: 0.0001315442641498521
 * min 0.0016940440982580185, max: 0.002468640683218837
sum eps on layers: tensor([2.7906, 0.3926, 0.8169], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.45
 * Lower 1 Val Acc 99.953, time 0.41
 * Upper 1 Val Acc 99.953, time 0.53
validation split name: 2
 *  Val Acc 98.139, time 0.46
 * Lower 1 Val Acc 97.845, time 0.48
 * Upper 1 Val Acc 97.845, time 0.45
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 92.666, Loss 0.268
 * , robust loss: 0.017 robust error: 0.00000000
 *  Val Acc 97.385, time 0.49
Epoch:1
LR: 0.001
 * Train Acc 97.896, Loss 0.075
 * , robust loss: 0.002 robust error: 0.00000000
 *  Val Acc 98.026, time 0.42
Epoch:2
LR: 0.001
 * Train Acc 98.402, Loss 0.056
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.506, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 98.668, Loss 0.046
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.719, time 0.44
Epoch:4
LR: 0.001
 * Train Acc 98.801, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.666, time 0.40
Epoch:5
LR: 0.001
 * Train Acc 98.766, Loss 0.039
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.453, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 98.766, Loss 0.037
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.559, time 0.51
Epoch:7
LR: 0.001
 * Train Acc 98.721, Loss 0.036
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.919, time 0.40
Epoch:8
LR: 0.001
 * Train Acc 98.721, Loss 0.036
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.346, time 0.41
Epoch:9
LR: 0.001
 * Train Acc 98.633, Loss 0.037
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.41
Epoch:10
LR: 0.001
 * Train Acc 98.508, Loss 0.038
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.453, time 0.42
Epoch:11
LR: 0.001
 * Train Acc 98.677, Loss 0.037
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.399, time 0.41
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1292.280517578125 -mean: 0.0031549816485494375 - std: 0.0011678558075800538
 * min 0.0005329169798642397, max: 0.0047956956550478935
sum: 108.16462707519531 -mean: 0.0006760288961231709 - std: 0.00018814248323906213
 * min 0.00019309137132950127, max: 0.001053035375662148
sum: 0.9977740049362183 - mean: 0.0012472175294533372 - std: 9.8547046945896e-05
 * min 0.0010499721392989159, max: 0.0014896966749802232
sum eps on layers: tensor([3.2307, 0.2704, 0.4989], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.47
 * Lower 1 Val Acc 99.953, time 0.44
 * Upper 1 Val Acc 99.953, time 0.45
validation split name: 2
 *  Val Acc 97.894, time 0.41
 * Lower 1 Val Acc 98.286, time 0.49
 * Upper 1 Val Acc 98.286, time 0.45
validation split name: 3
 *  Val Acc 98.399, time 0.39
 * Lower 1 Val Acc 90.288, time 0.39
 * Upper 1 Val Acc 90.288, time 0.43
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 95.018, Loss 0.206
 * , robust loss: 0.053 robust error: 0.00000000
 *  Val Acc 98.087, time 0.41
Epoch:1
LR: 0.001
 * Train Acc 99.072, Loss 0.045
 * , robust loss: 0.003 robust error: 0.00000000
 *  Val Acc 98.540, time 0.44
Epoch:2
LR: 0.001
 * Train Acc 99.253, Loss 0.028
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.741, time 0.40
Epoch:3
LR: 0.001
 * Train Acc 99.335, Loss 0.023
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.993, time 0.44
Epoch:4
LR: 0.001
 * Train Acc 99.425, Loss 0.019
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.892, time 0.42
Epoch:5
LR: 0.001
 * Train Acc 99.483, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.094, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 99.475, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.42
Epoch:7
LR: 0.001
 * Train Acc 99.450, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.46
Epoch:8
LR: 0.001
 * Train Acc 99.540, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.144, time 0.44
Epoch:9
LR: 0.001
 * Train Acc 99.508, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.446, time 0.44
Epoch:10
LR: 0.001
 * Train Acc 99.540, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.993, time 0.43
Epoch:11
LR: 0.001
 * Train Acc 99.532, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.396, time 0.43
after batch eps: 1.500000000000037, kappa: 0.5
sum: 530.98486328125 -mean: 0.0012963496847078204 - std: 0.0005575129180215299
 * min 0.00014910672325640917, max: 0.0021010430064052343
sum: 25.34100914001465 -mean: 0.0001583812991157174 - std: 4.7254048695322126e-05
 * min 3.905326229869388e-05, max: 0.00025208963779732585
sum: 0.21837055683135986 - mean: 0.00027296319603919983 - std: 2.49245495069772e-05
 * min 0.0002199552982347086, max: 0.00034193924511782825
sum eps on layers: tensor([1.3275, 0.0634, 0.1092], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.45
 * Lower 1 Val Acc 99.905, time 0.43
 * Upper 1 Val Acc 99.905, time 0.47
validation split name: 2
 *  Val Acc 97.062, time 0.50
 * Lower 1 Val Acc 97.698, time 0.48
 * Upper 1 Val Acc 97.698, time 0.39
validation split name: 3
 *  Val Acc 97.919, time 0.45
 * Lower 1 Val Acc 96.371, time 0.42
 * Upper 1 Val Acc 96.371, time 0.42
validation split name: 4
 *  Val Acc 99.396, time 0.42
 * Lower 1 Val Acc 99.245, time 0.43
 * Upper 1 Val Acc 99.245, time 0.41
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 87.924, Loss 0.366
 * , robust loss: 0.129 robust error: 0.01000000
 *  Val Acc 93.394, time 0.45
Epoch:1
LR: 0.001
 * Train Acc 93.805, Loss 0.148
 * , robust loss: 0.019 robust error: 0.00000000
 *  Val Acc 94.453, time 0.49
Epoch:2
LR: 0.001
 * Train Acc 94.797, Loss 0.098
 * , robust loss: 0.004 robust error: 0.00000000
 *  Val Acc 95.008, time 0.46
Epoch:3
LR: 0.001
 * Train Acc 95.432, Loss 0.082
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 95.663, time 0.42
Epoch:4
LR: 0.001
 * Train Acc 95.805, Loss 0.074
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.016, time 0.45
Epoch:5
LR: 0.001
 * Train Acc 95.932, Loss 0.068
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.663, time 0.47
Epoch:6
LR: 0.001
 * Train Acc 96.288, Loss 0.064
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.319, time 0.46
Epoch:7
LR: 0.001
 * Train Acc 96.432, Loss 0.061
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.117, time 0.47
Epoch:8
LR: 0.001
 * Train Acc 96.627, Loss 0.059
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.470, time 0.46
Epoch:9
LR: 0.001
 * Train Acc 96.669, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.319, time 0.42
Epoch:10
LR: 0.001
 * Train Acc 96.636, Loss 0.056
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.369, time 0.47
Epoch:11
LR: 0.001
 * Train Acc 96.737, Loss 0.055
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.470, time 0.45
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 383.6278076171875 -mean: 0.0009365912992507219 - std: 0.0004892385913990438
 * min 4.245289528626017e-05, max: 0.0016641017282381654
sum: 6.238615989685059 -mean: 3.8991347537375987e-05 - std: 1.2696151316049509e-05
 * min 7.427198852383299e-06, max: 6.604141526622698e-05
sum: 0.05066775530576706 - mean: 6.333469355013222e-05 - std: 5.699347639165353e-06
 * min 5.1420349336694926e-05, max: 7.900857599452138e-05
sum eps on layers: tensor([0.9591, 0.0156, 0.0253], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.47
 * Lower 1 Val Acc 99.905, time 0.47
 * Upper 1 Val Acc 99.905, time 0.49
validation split name: 2
 *  Val Acc 97.209, time 0.50
 * Lower 1 Val Acc 97.796, time 0.43
 * Upper 1 Val Acc 97.796, time 0.39
validation split name: 3
 *  Val Acc 98.132, time 0.44
 * Lower 1 Val Acc 97.439, time 0.37
 * Upper 1 Val Acc 97.439, time 0.42
validation split name: 4
 *  Val Acc 99.245, time 0.42
 * Lower 1 Val Acc 99.245, time 0.42
 * Upper 1 Val Acc 99.245, time 0.52
validation split name: 5
 *  Val Acc 96.470, time 0.43
 * Lower 1 Val Acc 95.966, time 0.42
 * Upper 1 Val Acc 95.966, time 0.41
Task 1 average acc: 99.95271867612293
Task 2 average acc: 99.04589900505461
Task 3 average acc: 98.74869541301723
Task 4 average acc: 98.57045050781473
Task 5 average acc: 98.1922203095658
===Summary of experiment repeats: 3 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757 98.19222031  0.          0.          0.
  0.          0.          0.          0.        ]
mean: 29.299862376621398 std: 44.756751377821956
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.313, Loss 0.020
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.45
Epoch:1
LR: 0.001
 * Train Acc 99.897, Loss 0.004
 * , robust loss: 0.009 robust error: 0.00000000
 *  Val Acc 99.953, time 0.44
Epoch:2
LR: 0.001
 * Train Acc 99.937, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
Epoch:3
LR: 0.001
 * Train Acc 99.945, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.46
Epoch:4
LR: 0.001
 * Train Acc 99.945, Loss 0.002
 * , robust loss: 0.002 robust error: 0.00000000
 *  Val Acc 100.000, time 0.43
Epoch:5
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.42
Epoch:6
LR: 0.001
 * Train Acc 99.992, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.47
Epoch:7
LR: 0.001
 * Train Acc 99.992, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
Epoch:8
LR: 0.001
 * Train Acc 99.992, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.42
Epoch:9
LR: 0.001
 * Train Acc 99.976, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.43
Epoch:10
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
Epoch:11
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.46
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1295.3013916015625 -mean: 0.0031623567920178175 - std: 0.0003571386041585356
 * min 0.0018084916519001126, max: 0.003639217233285308
sum: 695.3596801757812 -mean: 0.004345997702330351 - std: 0.00038288868381641805
 * min 0.0029446231201291084, max: 0.005270230583846569
sum: 6.046695709228516 - mean: 0.007558369543403387 - std: 0.00023750706168357283
 * min 0.0067755295895040035, max: 0.008447028696537018
sum eps on layers: tensor([3.2383, 1.7384, 3.0233], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.52
 * Lower 1 Val Acc 99.953, time 0.43
 * Upper 1 Val Acc 99.953, time 0.44
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 93.465, Loss 0.190
 * , robust loss: 0.079 robust error: 0.03370787
 *  Val Acc 97.502, time 0.43
Epoch:1
LR: 0.001
 * Train Acc 97.039, Loss 0.068
 * , robust loss: 0.010 robust error: 0.00000000
 *  Val Acc 97.600, time 0.45
Epoch:2
LR: 0.001
 * Train Acc 97.179, Loss 0.048
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 96.866, time 0.40
Epoch:3
LR: 0.001
 * Train Acc 97.088, Loss 0.048
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.845, time 0.40
Epoch:4
LR: 0.001
 * Train Acc 97.477, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.992, time 0.44
Epoch:5
LR: 0.001
 * Train Acc 97.651, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.943, time 0.47
Epoch:6
LR: 0.001
 * Train Acc 97.543, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.747, time 0.44
Epoch:7
LR: 0.001
 * Train Acc 97.626, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.405, time 0.41
Epoch:8
LR: 0.001
 * Train Acc 97.444, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.992, time 0.48
Epoch:9
LR: 0.001
 * Train Acc 97.361, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.698, time 0.41
Epoch:10
LR: 0.001
 * Train Acc 97.378, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.453, time 0.51
Epoch:11
LR: 0.001
 * Train Acc 97.659, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.698, time 0.47
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1143.831298828125 -mean: 0.002792556770145893 - std: 0.00091343600070104
 * min 0.0006377096869982779, max: 0.004051391500979662
sum: 156.17462158203125 -mean: 0.0009760913671925664 - std: 0.0002496048982720822
 * min 0.0003214742464479059, max: 0.0014972088392823935
sum: 1.4999709129333496 - mean: 0.0018749636365100741 - std: 0.00011540847481228411
 * min 0.0015279257204383612, max: 0.0023194989189505577
sum eps on layers: tensor([2.8596, 0.3904, 0.7500], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.48
 * Lower 1 Val Acc 99.953, time 0.42
 * Upper 1 Val Acc 99.953, time 0.47
validation split name: 2
 *  Val Acc 97.698, time 0.41
 * Lower 1 Val Acc 96.180, time 0.45
 * Upper 1 Val Acc 96.180, time 0.42
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 89.949, Loss 0.302
 * , robust loss: 0.025 robust error: 0.00000000
 *  Val Acc 95.998, time 0.46
Epoch:1
LR: 0.001
 * Train Acc 96.928, Loss 0.088
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 97.705, time 0.43
Epoch:2
LR: 0.001
 * Train Acc 97.985, Loss 0.064
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.026, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 98.428, Loss 0.053
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.239, time 0.40
Epoch:4
LR: 0.001
 * Train Acc 98.482, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.48
Epoch:5
LR: 0.001
 * Train Acc 98.482, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.506, time 0.43
Epoch:6
LR: 0.001
 * Train Acc 98.562, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.40
Epoch:7
LR: 0.001
 * Train Acc 98.375, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.239, time 0.43
Epoch:8
LR: 0.001
 * Train Acc 98.428, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.346, time 0.42
Epoch:9
LR: 0.001
 * Train Acc 98.331, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.866, time 0.46
Epoch:10
LR: 0.001
 * Train Acc 98.118, Loss 0.046
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.132, time 0.44
Epoch:11
LR: 0.001
 * Train Acc 97.976, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.972, time 0.41
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1328.516357421875 -mean: 0.003243447979912162 - std: 0.0012278511421754956
 * min 0.0005452846526168287, max: 0.0049584051594138145
sum: 100.74515533447266 -mean: 0.0006296571809798479 - std: 0.00018067906785290688
 * min 0.00017659396689850837, max: 0.000978647032752633
sum: 0.8536931276321411 - mean: 0.001067116390913725 - std: 8.219097799155861e-05
 * min 0.0008949353359639645, max: 0.0012788547901436687
sum eps on layers: tensor([3.3213, 0.2519, 0.4268], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.44
 * Lower 1 Val Acc 99.953, time 0.48
 * Upper 1 Val Acc 99.953, time 0.44
validation split name: 2
 *  Val Acc 97.013, time 0.46
 * Lower 1 Val Acc 96.180, time 0.46
 * Upper 1 Val Acc 96.180, time 0.44
validation split name: 3
 *  Val Acc 97.972, time 0.48
 * Lower 1 Val Acc 93.383, time 0.40
 * Upper 1 Val Acc 93.383, time 0.42
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.221, Loss 0.256
 * , robust loss: 0.039 robust error: 0.00000000
 *  Val Acc 98.489, time 0.43
Epoch:1
LR: 0.001
 * Train Acc 98.966, Loss 0.059
 * , robust loss: 0.003 robust error: 0.00000000
 *  Val Acc 98.842, time 0.40
Epoch:2
LR: 0.001
 * Train Acc 99.138, Loss 0.036
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 98.993, time 0.40
Epoch:3
LR: 0.001
 * Train Acc 99.261, Loss 0.028
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.842, time 0.42
Epoch:4
LR: 0.001
 * Train Acc 99.269, Loss 0.024
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.043, time 0.44
Epoch:5
LR: 0.001
 * Train Acc 99.368, Loss 0.021
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.144, time 0.44
Epoch:6
LR: 0.001
 * Train Acc 99.368, Loss 0.019
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.094, time 0.46
Epoch:7
LR: 0.001
 * Train Acc 99.409, Loss 0.018
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.043, time 0.56
Epoch:8
LR: 0.001
 * Train Acc 99.384, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.094, time 0.46
Epoch:9
LR: 0.001
 * Train Acc 99.425, Loss 0.016
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.47
Epoch:10
LR: 0.001
 * Train Acc 99.409, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.043, time 0.43
Epoch:11
LR: 0.001
 * Train Acc 99.384, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.40
after batch eps: 1.500000000000037, kappa: 0.5
sum: 540.9833984375 -mean: 0.0013207602314651012 - std: 0.0005791268777102232
 * min 0.000145207392051816, max: 0.0021675715688616037
sum: 22.73357391357422 -mean: 0.0001420848275301978 - std: 4.4103082473156974e-05
 * min 3.4733293432509527e-05, max: 0.00022715718660037965
sum: 0.1814156472682953 - mean: 0.0002267695526825264 - std: 1.8485254258848727e-05
 * min 0.0001841057528508827, max: 0.000282605440588668
sum eps on layers: tensor([1.3525, 0.0568, 0.0907], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.41
 * Lower 1 Val Acc 100.000, time 0.45
 * Upper 1 Val Acc 100.000, time 0.43
validation split name: 2
 *  Val Acc 97.258, time 0.45
 * Lower 1 Val Acc 97.453, time 0.47
 * Upper 1 Val Acc 97.453, time 0.45
validation split name: 3
 *  Val Acc 93.330, time 0.48
 * Lower 1 Val Acc 91.409, time 0.45
 * Upper 1 Val Acc 91.409, time 0.44
validation split name: 4
 *  Val Acc 99.194, time 0.41
 * Lower 1 Val Acc 99.245, time 0.42
 * Upper 1 Val Acc 99.245, time 0.41
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 86.644, Loss 0.367
 * , robust loss: 0.125 robust error: 0.02000000
 *  Val Acc 92.738, time 0.49
Epoch:1
LR: 0.001
 * Train Acc 93.288, Loss 0.155
 * , robust loss: 0.028 robust error: 0.00000000
 *  Val Acc 95.108, time 0.47
Epoch:2
LR: 0.001
 * Train Acc 94.593, Loss 0.102
 * , robust loss: 0.007 robust error: 0.00000000
 *  Val Acc 95.613, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 95.280, Loss 0.083
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 95.461, time 0.49
Epoch:4
LR: 0.001
 * Train Acc 95.788, Loss 0.075
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.672, time 0.38
Epoch:5
LR: 0.001
 * Train Acc 96.186, Loss 0.069
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.520, time 0.47
Epoch:6
LR: 0.001
 * Train Acc 96.254, Loss 0.065
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.571, time 0.50
Epoch:7
LR: 0.001
 * Train Acc 96.407, Loss 0.062
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.571, time 0.43
Epoch:8
LR: 0.001
 * Train Acc 96.576, Loss 0.059
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.470, time 0.49
Epoch:9
LR: 0.001
 * Train Acc 96.492, Loss 0.058
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.773, time 0.51
Epoch:10
LR: 0.001
 * Train Acc 96.746, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.924, time 0.43
Epoch:11
LR: 0.001
 * Train Acc 96.686, Loss 0.056
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.672, time 0.47
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 385.37677001953125 -mean: 0.0009408612386323512 - std: 0.0004951903247274458
 * min 4.355904457042925e-05, max: 0.0016812955727800727
sum: 5.821059226989746 -mean: 3.63816179742571e-05 - std: 1.2269796570762992e-05
 * min 6.4965561250573955e-06, max: 5.9875426813960075e-05
sum: 0.044010914862155914 - mean: 5.501364285009913e-05 - std: 4.880439064436359e-06
 * min 4.324933252064511e-05, max: 7.126998389139771e-05
sum eps on layers: tensor([0.9634, 0.0146, 0.0220], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.50
 * Lower 1 Val Acc 99.953, time 0.55
 * Upper 1 Val Acc 99.953, time 0.57
validation split name: 2
 *  Val Acc 97.258, time 0.46
 * Lower 1 Val Acc 97.502, time 0.59
 * Upper 1 Val Acc 97.502, time 0.47
validation split name: 3
 *  Val Acc 97.012, time 0.45
 * Lower 1 Val Acc 96.958, time 0.40
 * Upper 1 Val Acc 96.958, time 0.39
validation split name: 4
 *  Val Acc 98.993, time 0.40
 * Lower 1 Val Acc 99.094, time 0.44
 * Upper 1 Val Acc 99.094, time 0.40
validation split name: 5
 *  Val Acc 96.672, time 0.42
 * Lower 1 Val Acc 96.621, time 0.48
 * Upper 1 Val Acc 96.621, time 0.48
Task 1 average acc: 99.95271867612293
Task 2 average acc: 98.8255268209214
Task 3 average acc: 98.31256771962298
Task 4 average acc: 97.44543175039718
Task 5 average acc: 97.9773418107245
===Summary of experiment repeats: 4 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757 98.19222031 97.97734181  0.          0.
  0.          0.          0.          0.        ]
mean: 39.09759655769385 std: 47.88509813529134
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.313, Loss 0.021
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.44
Epoch:1
LR: 0.001
 * Train Acc 99.897, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.858, time 0.46
Epoch:2
LR: 0.001
 * Train Acc 99.945, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.41
Epoch:3
LR: 0.001
 * Train Acc 99.953, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.48
Epoch:4
LR: 0.001
 * Train Acc 99.953, Loss 0.001
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 99.953, time 0.49
Epoch:5
LR: 0.001
 * Train Acc 99.984, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.46
Epoch:6
LR: 0.001
 * Train Acc 99.976, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.858, time 0.45
Epoch:7
LR: 0.001
 * Train Acc 99.921, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.858, time 0.45
Epoch:8
LR: 0.001
 * Train Acc 99.968, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.47
Epoch:9
LR: 0.001
 * Train Acc 99.976, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.46
Epoch:10
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.44
Epoch:11
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.43
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1321.9583740234375 -mean: 0.0032274373807013035 - std: 0.0003939616435673088
 * min 0.0016451250994578004, max: 0.003765758126974106
sum: 687.2010498046875 -mean: 0.0042950063943862915 - std: 0.0003920929739251733
 * min 0.002615733304992318, max: 0.005272146314382553
sum: 5.9542036056518555 - mean: 0.007442754227668047 - std: 0.00025665483553893864
 * min 0.006589258089661598, max: 0.008425639010965824
sum eps on layers: tensor([3.3049, 1.7180, 2.9771], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.41
 * Lower 1 Val Acc 99.953, time 0.43
 * Upper 1 Val Acc 99.953, time 0.46
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.540, Loss 0.164
 * , robust loss: 0.051 robust error: 0.01123596
 *  Val Acc 97.502, time 0.43
Epoch:1
LR: 0.001
 * Train Acc 97.146, Loss 0.064
 * , robust loss: 0.007 robust error: 0.00000000
 *  Val Acc 97.013, time 0.45
Epoch:2
LR: 0.001
 * Train Acc 97.287, Loss 0.048
 * , robust loss: 0.002 robust error: 0.00000000
 *  Val Acc 98.335, time 0.39
Epoch:3
LR: 0.001
 * Train Acc 97.361, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.747, time 0.45
Epoch:4
LR: 0.001
 * Train Acc 97.403, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.286, time 0.48
Epoch:5
LR: 0.001
 * Train Acc 97.585, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.531, time 0.51
Epoch:6
LR: 0.001
 * Train Acc 97.394, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.139, time 0.48
Epoch:7
LR: 0.001
 * Train Acc 97.485, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.062, time 0.40
Epoch:8
LR: 0.001
 * Train Acc 97.436, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.384, time 0.39
Epoch:9
LR: 0.001
 * Train Acc 97.444, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.943, time 0.50
Epoch:10
LR: 0.001
 * Train Acc 97.452, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.894, time 0.43
Epoch:11
LR: 0.001
 * Train Acc 97.452, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.502, time 0.48
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1138.0830078125 -mean: 0.002778522903099656 - std: 0.0009160604095086455
 * min 0.000624094158411026, max: 0.004016407765448093
sum: 158.30068969726562 -mean: 0.0009893792448565364 - std: 0.0002554415841586888
 * min 0.0003288044536020607, max: 0.0015322251711040735
sum: 1.5180810689926147 - mean: 0.0018976012943312526 - std: 0.00011024084960808977
 * min 0.0016260313568636775, max: 0.002222768496721983
sum eps on layers: tensor([2.8452, 0.3958, 0.7590], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.41
 * Lower 1 Val Acc 99.953, time 0.53
 * Upper 1 Val Acc 99.953, time 0.51
validation split name: 2
 *  Val Acc 97.502, time 0.47
 * Lower 1 Val Acc 97.062, time 0.49
 * Upper 1 Val Acc 97.062, time 0.46
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 91.441, Loss 0.278
 * , robust loss: 0.017 robust error: 0.00000000
 *  Val Acc 96.905, time 0.47
Epoch:1
LR: 0.001
 * Train Acc 97.434, Loss 0.074
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 97.866, time 0.44
Epoch:2
LR: 0.001
 * Train Acc 97.985, Loss 0.056
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.599, time 0.40
Epoch:3
LR: 0.001
 * Train Acc 98.446, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.506, time 0.38
Epoch:4
LR: 0.001
 * Train Acc 98.411, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.613, time 0.46
Epoch:5
LR: 0.001
 * Train Acc 98.331, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.666, time 0.37
Epoch:6
LR: 0.001
 * Train Acc 98.384, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.346, time 0.46
Epoch:7
LR: 0.001
 * Train Acc 98.304, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.079, time 0.43
Epoch:8
LR: 0.001
 * Train Acc 98.233, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.132, time 0.45
Epoch:9
LR: 0.001
 * Train Acc 98.153, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.453, time 0.48
Epoch:10
LR: 0.001
 * Train Acc 98.011, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.42
Epoch:11
LR: 0.001
 * Train Acc 98.020, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.42
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1313.0621337890625 -mean: 0.003205718006938696 - std: 0.0011938363313674927
 * min 0.0005596629926003516, max: 0.004836720414459705
sum: 106.89215850830078 -mean: 0.0006680759834125638 - std: 0.0001901503565022722
 * min 0.0001878828479675576, max: 0.0010401211911812425
sum: 0.9002282023429871 - mean: 0.001125285285525024 - std: 9.108255471801385e-05
 * min 0.0009438921697437763, max: 0.001348651829175651
sum eps on layers: tensor([3.2827, 0.2672, 0.4501], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.48
 * Lower 1 Val Acc 99.953, time 0.43
 * Upper 1 Val Acc 99.953, time 0.47
validation split name: 2
 *  Val Acc 96.523, time 0.45
 * Lower 1 Val Acc 96.033, time 0.45
 * Upper 1 Val Acc 96.033, time 0.43
validation split name: 3
 *  Val Acc 98.292, time 0.40
 * Lower 1 Val Acc 91.622, time 0.38
 * Upper 1 Val Acc 91.622, time 0.40
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 95.740, Loss 0.203
 * , robust loss: 0.029 robust error: 0.00000000
 *  Val Acc 98.087, time 0.48
Epoch:1
LR: 0.001
 * Train Acc 99.007, Loss 0.044
 * , robust loss: 0.006 robust error: 0.00000000
 *  Val Acc 98.489, time 0.43
Epoch:2
LR: 0.001
 * Train Acc 99.302, Loss 0.028
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.842, time 0.53
Epoch:3
LR: 0.001
 * Train Acc 99.352, Loss 0.022
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.094, time 0.52
Epoch:4
LR: 0.001
 * Train Acc 99.483, Loss 0.019
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.892, time 0.43
Epoch:5
LR: 0.001
 * Train Acc 99.442, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.043, time 0.48
Epoch:6
LR: 0.001
 * Train Acc 99.458, Loss 0.016
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.144, time 0.43
Epoch:7
LR: 0.001
 * Train Acc 99.516, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.41
Epoch:8
LR: 0.001
 * Train Acc 99.499, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.51
Epoch:9
LR: 0.001
 * Train Acc 99.442, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.245, time 0.40
Epoch:10
LR: 0.001
 * Train Acc 99.499, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.47
Epoch:11
LR: 0.001
 * Train Acc 99.475, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.993, time 0.48
after batch eps: 1.500000000000037, kappa: 0.5
sum: 535.040771484375 -mean: 0.0013062518555670977 - std: 0.0005563058657571673
 * min 0.00015931151574477553, max: 0.002097813179716468
sum: 25.234622955322266 -mean: 0.00015771639300510287 - std: 4.7998575610108674e-05
 * min 3.90644563594833e-05, max: 0.00025641656247898936
sum: 0.1986236274242401 - mean: 0.000248279538936913 - std: 2.2176849597599357e-05
 * min 0.00020178734848741442, max: 0.00030838645761832595
sum eps on layers: tensor([1.3376, 0.0631, 0.0993], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.43
 * Lower 1 Val Acc 99.953, time 0.50
 * Upper 1 Val Acc 99.953, time 0.45
validation split name: 2
 *  Val Acc 95.005, time 0.44
 * Lower 1 Val Acc 95.152, time 0.43
 * Upper 1 Val Acc 95.152, time 0.42
validation split name: 3
 *  Val Acc 96.478, time 0.44
 * Lower 1 Val Acc 94.450, time 0.41
 * Upper 1 Val Acc 94.450, time 0.42
validation split name: 4
 *  Val Acc 98.993, time 0.43
 * Lower 1 Val Acc 98.993, time 0.50
 * Upper 1 Val Acc 98.993, time 0.49
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 86.712, Loss 0.381
 * , robust loss: 0.122 robust error: 0.02000000
 *  Val Acc 93.091, time 0.44
Epoch:1
LR: 0.001
 * Train Acc 93.449, Loss 0.152
 * , robust loss: 0.039 robust error: 0.01000000
 *  Val Acc 94.907, time 0.47
Epoch:2
LR: 0.001
 * Train Acc 94.568, Loss 0.101
 * , robust loss: 0.006 robust error: 0.00000000
 *  Val Acc 94.856, time 0.43
Epoch:3
LR: 0.001
 * Train Acc 95.254, Loss 0.083
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 95.562, time 0.49
Epoch:4
LR: 0.001
 * Train Acc 95.500, Loss 0.075
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.814, time 0.47
Epoch:5
LR: 0.001
 * Train Acc 95.814, Loss 0.070
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.814, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 95.983, Loss 0.067
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.218, time 0.41
Epoch:7
LR: 0.001
 * Train Acc 96.102, Loss 0.064
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.814, time 0.46
Epoch:8
LR: 0.001
 * Train Acc 96.144, Loss 0.062
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.218, time 0.39
Epoch:9
LR: 0.001
 * Train Acc 96.136, Loss 0.061
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.621, time 0.48
Epoch:10
LR: 0.001
 * Train Acc 96.347, Loss 0.059
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.571, time 0.53
Epoch:11
LR: 0.001
 * Train Acc 96.534, Loss 0.058
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.571, time 0.53
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 385.1922912597656 -mean: 0.0009404108277522027 - std: 0.0004933789023198187
 * min 4.4983713451074436e-05, max: 0.001721409847959876
sum: 5.9769206047058105 -mean: 3.735575228347443e-05 - std: 1.2425951354089193e-05
 * min 7.593187092425069e-06, max: 6.355631921906024e-05
sum: 0.04415386542677879 - mean: 5.5192329455167055e-05 - std: 5.205402885621879e-06
 * min 4.2496048990869895e-05, max: 7.352667307714e-05
sum eps on layers: tensor([0.9630, 0.0149, 0.0221], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.42
 * Lower 1 Val Acc 99.953, time 0.44
 * Upper 1 Val Acc 99.953, time 0.47
validation split name: 2
 *  Val Acc 95.005, time 0.51
 * Lower 1 Val Acc 95.201, time 0.44
 * Upper 1 Val Acc 95.201, time 0.45
validation split name: 3
 *  Val Acc 96.158, time 0.40
 * Lower 1 Val Acc 94.557, time 0.47
 * Upper 1 Val Acc 94.557, time 0.43
validation split name: 4
 *  Val Acc 97.986, time 0.38
 * Lower 1 Val Acc 98.036, time 0.46
 * Upper 1 Val Acc 98.036, time 0.48
validation split name: 5
 *  Val Acc 96.571, time 0.46
 * Lower 1 Val Acc 96.672, time 0.45
 * Upper 1 Val Acc 96.672, time 0.44
Task 1 average acc: 99.95271867612293
Task 2 average acc: 98.72758362797332
Task 3 average acc: 98.25605265062198
Task 4 average acc: 97.60717203881009
Task 5 average acc: 97.13446405923192
===Summary of experiment repeats: 5 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757 98.19222031 97.97734181 97.13446406  0.
  0.          0.          0.          0.        ]
mean: 48.81104296361704 std: 48.811854867706366
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.139, Loss 0.024
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.45
Epoch:1
LR: 0.001
 * Train Acc 99.882, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.57
Epoch:2
LR: 0.001
 * Train Acc 99.945, Loss 0.002
 * , robust loss: 0.012 robust error: 0.01538462
 *  Val Acc 99.953, time 0.49
Epoch:3
LR: 0.001
 * Train Acc 99.945, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.42
Epoch:4
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.60
Epoch:5
LR: 0.001
 * Train Acc 99.984, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.53
Epoch:6
LR: 0.001
 * Train Acc 99.984, Loss 0.001
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 99.953, time 0.43
Epoch:7
LR: 0.001
 * Train Acc 99.968, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.44
Epoch:8
LR: 0.001
 * Train Acc 99.858, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.42
Epoch:9
LR: 0.001
 * Train Acc 99.945, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.48
Epoch:10
LR: 0.001
 * Train Acc 99.976, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.43
Epoch:11
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.45
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1334.1845703125 -mean: 0.0032572865020483732 - std: 0.00041198640246875584
 * min 0.0016191652975976467, max: 0.0038256437983363867
sum: 653.3406372070312 -mean: 0.004083378706127405 - std: 0.00041306682396680117
 * min 0.00238657440058887, max: 0.005089490674436092
sum: 6.062373638153076 - mean: 0.007577966898679733 - std: 0.0003595711605157703
 * min 0.006506451405584812, max: 0.008859255351126194
sum eps on layers: tensor([3.3355, 1.6334, 3.0312], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.41
 * Lower 1 Val Acc 99.953, time 0.49
 * Upper 1 Val Acc 99.953, time 0.46
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 93.498, Loss 0.198
 * , robust loss: 0.072 robust error: 0.02247191
 *  Val Acc 96.572, time 0.52
Epoch:1
LR: 0.001
 * Train Acc 96.625, Loss 0.078
 * , robust loss: 0.014 robust error: 0.01123596
 *  Val Acc 97.258, time 0.42
Epoch:2
LR: 0.001
 * Train Acc 96.981, Loss 0.052
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 97.796, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 97.179, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.600, time 0.46
Epoch:4
LR: 0.001
 * Train Acc 97.378, Loss 0.046
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.845, time 0.49
Epoch:5
LR: 0.001
 * Train Acc 97.419, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.188, time 0.48
Epoch:6
LR: 0.001
 * Train Acc 97.634, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.258, time 0.40
Epoch:7
LR: 0.001
 * Train Acc 97.394, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.621, time 0.45
Epoch:8
LR: 0.001
 * Train Acc 97.345, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.894, time 0.47
Epoch:9
LR: 0.001
 * Train Acc 97.353, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.649, time 0.49
Epoch:10
LR: 0.001
 * Train Acc 97.494, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.405, time 0.46
Epoch:11
LR: 0.001
 * Train Acc 97.461, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.139, time 0.44
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1142.6517333984375 -mean: 0.002789677120745182 - std: 0.0008984091109596193
 * min 0.0005711035919375718, max: 0.004081592429429293
sum: 153.81365966796875 -mean: 0.0009613353759050369 - std: 0.00024665065575391054
 * min 0.00030089126084931195, max: 0.0014624749310314655
sum: 1.5176726579666138 - mean: 0.0018970908131450415 - std: 0.00013024504005443305
 * min 0.001513659954071045, max: 0.0023999111726880074
sum eps on layers: tensor([2.8566, 0.3845, 0.7588], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.38
 * Lower 1 Val Acc 100.000, time 0.47
 * Upper 1 Val Acc 100.000, time 0.40
validation split name: 2
 *  Val Acc 98.139, time 0.46
 * Lower 1 Val Acc 98.090, time 0.43
 * Upper 1 Val Acc 98.090, time 0.45
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 90.136, Loss 0.299
 * , robust loss: 0.023 robust error: 0.00000000
 *  Val Acc 96.425, time 0.48
Epoch:1
LR: 0.001
 * Train Acc 97.248, Loss 0.082
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 98.132, time 0.39
Epoch:2
LR: 0.001
 * Train Acc 97.993, Loss 0.061
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.41
Epoch:3
LR: 0.001
 * Train Acc 98.349, Loss 0.052
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.666, time 0.41
Epoch:4
LR: 0.001
 * Train Acc 98.686, Loss 0.046
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.719, time 0.40
Epoch:5
LR: 0.001
 * Train Acc 98.686, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.666, time 0.44
Epoch:6
LR: 0.001
 * Train Acc 98.757, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.613, time 0.49
Epoch:7
LR: 0.001
 * Train Acc 98.748, Loss 0.039
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.666, time 0.43
Epoch:8
LR: 0.001
 * Train Acc 98.748, Loss 0.039
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.613, time 0.40
Epoch:9
LR: 0.001
 * Train Acc 98.784, Loss 0.039
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.666, time 0.43
Epoch:10
LR: 0.001
 * Train Acc 98.597, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.773, time 0.42
Epoch:11
LR: 0.001
 * Train Acc 98.642, Loss 0.039
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.613, time 0.44
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1316.450927734375 -mean: 0.0032139914110302925 - std: 0.0011895985808223486
 * min 0.0004879129701294005, max: 0.004936853423714638
sum: 102.52969360351562 -mean: 0.000640810583718121 - std: 0.0001843621430452913
 * min 0.00017674143600743264, max: 0.0009987864177674055
sum: 0.9050965309143066 - mean: 0.0011313706636428833 - std: 9.058269642991945e-05
 * min 0.0009384420118294656, max: 0.0013716391986235976
sum eps on layers: tensor([3.2911, 0.2563, 0.4525], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.52
 * Lower 1 Val Acc 100.000, time 0.47
 * Upper 1 Val Acc 100.000, time 0.58
validation split name: 2
 *  Val Acc 97.992, time 0.46
 * Lower 1 Val Acc 97.698, time 0.43
 * Upper 1 Val Acc 97.698, time 0.47
validation split name: 3
 *  Val Acc 98.613, time 0.41
 * Lower 1 Val Acc 97.599, time 0.41
 * Upper 1 Val Acc 97.599, time 0.40
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.033, Loss 0.263
 * , robust loss: 0.055 robust error: 0.00000000
 *  Val Acc 98.137, time 0.45
Epoch:1
LR: 0.001
 * Train Acc 98.974, Loss 0.060
 * , robust loss: 0.005 robust error: 0.00000000
 *  Val Acc 98.590, time 0.41
Epoch:2
LR: 0.001
 * Train Acc 99.278, Loss 0.035
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 98.792, time 0.40
Epoch:3
LR: 0.001
 * Train Acc 99.417, Loss 0.027
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.892, time 0.45
Epoch:4
LR: 0.001
 * Train Acc 99.491, Loss 0.023
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.792, time 0.49
Epoch:5
LR: 0.001
 * Train Acc 99.491, Loss 0.021
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.144, time 0.44
Epoch:6
LR: 0.001
 * Train Acc 99.549, Loss 0.019
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.892, time 0.48
Epoch:7
LR: 0.001
 * Train Acc 99.590, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.245, time 0.42
Epoch:8
LR: 0.001
 * Train Acc 99.598, Loss 0.016
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.144, time 0.49
Epoch:9
LR: 0.001
 * Train Acc 99.557, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.43
Epoch:10
LR: 0.001
 * Train Acc 99.524, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.42
Epoch:11
LR: 0.001
 * Train Acc 99.532, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.144, time 0.50
after batch eps: 1.500000000000037, kappa: 0.5
sum: 539.1682739257812 -mean: 0.0013163287658244371 - std: 0.0005679895984940231
 * min 0.00013051769929006696, max: 0.002173319458961487
sum: 22.990880966186523 -mean: 0.0001436930033378303 - std: 4.483354859985411e-05
 * min 3.085665957769379e-05, max: 0.00023225424229167402
sum: 0.18920451402664185 - mean: 0.0002365056425333023 - std: 2.1224974261713214e-05
 * min 0.00018762945546768606, max: 0.0003025317273568362
sum eps on layers: tensor([1.3479, 0.0575, 0.0946], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.46
 * Lower 1 Val Acc 99.953, time 0.47
 * Upper 1 Val Acc 99.953, time 0.44
validation split name: 2
 *  Val Acc 97.649, time 0.44
 * Lower 1 Val Acc 96.915, time 0.49
 * Upper 1 Val Acc 96.915, time 0.41
validation split name: 3
 *  Val Acc 98.399, time 0.42
 * Lower 1 Val Acc 98.453, time 0.43
 * Upper 1 Val Acc 98.453, time 0.39
validation split name: 4
 *  Val Acc 99.144, time 0.40
 * Lower 1 Val Acc 98.892, time 0.44
 * Upper 1 Val Acc 98.892, time 0.43
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 86.856, Loss 0.376
 * , robust loss: 0.208 robust error: 0.05000000
 *  Val Acc 91.931, time 0.43
Epoch:1
LR: 0.001
 * Train Acc 93.051, Loss 0.167
 * , robust loss: 0.042 robust error: 0.00000000
 *  Val Acc 93.747, time 0.43
Epoch:2
LR: 0.001
 * Train Acc 94.186, Loss 0.110
 * , robust loss: 0.010 robust error: 0.00000000
 *  Val Acc 94.352, time 0.45
Epoch:3
LR: 0.001
 * Train Acc 95.119, Loss 0.091
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 95.260, time 0.45
Epoch:4
LR: 0.001
 * Train Acc 95.407, Loss 0.081
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.915, time 0.42
Epoch:5
LR: 0.001
 * Train Acc 95.712, Loss 0.074
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.865, time 0.51
Epoch:6
LR: 0.001
 * Train Acc 96.102, Loss 0.070
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.369, time 0.44
Epoch:7
LR: 0.001
 * Train Acc 96.220, Loss 0.066
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.268, time 0.44
Epoch:8
LR: 0.001
 * Train Acc 96.568, Loss 0.063
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.571, time 0.44
Epoch:9
LR: 0.001
 * Train Acc 96.517, Loss 0.061
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.067, time 0.43
Epoch:10
LR: 0.001
 * Train Acc 96.686, Loss 0.059
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.773, time 0.42
Epoch:11
LR: 0.001
 * Train Acc 96.720, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.672, time 0.46
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 385.3096923828125 -mean: 0.0009406974422745407 - std: 0.000492219056468457
 * min 3.7327074096538126e-05, max: 0.0016993576427921653
sum: 5.761603832244873 -mean: 3.601002390496433e-05 - std: 1.2288955076655839e-05
 * min 5.9629678617056925e-06, max: 5.994122693664394e-05
sum: 0.04464344680309296 - mean: 5.5804306612117216e-05 - std: 5.957876510365168e-06
 * min 4.327124770497903e-05, max: 7.327337516471744e-05
sum eps on layers: tensor([0.9633, 0.0144, 0.0223], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.44
 * Lower 1 Val Acc 99.953, time 0.51
 * Upper 1 Val Acc 99.953, time 0.45
validation split name: 2
 *  Val Acc 97.307, time 0.44
 * Lower 1 Val Acc 96.670, time 0.45
 * Upper 1 Val Acc 96.670, time 0.49
validation split name: 3
 *  Val Acc 98.399, time 0.48
 * Lower 1 Val Acc 98.666, time 0.46
 * Upper 1 Val Acc 98.666, time 0.41
validation split name: 4
 *  Val Acc 98.691, time 0.51
 * Lower 1 Val Acc 98.691, time 0.47
 * Upper 1 Val Acc 98.691, time 0.53
validation split name: 5
 *  Val Acc 96.672, time 0.49
 * Lower 1 Val Acc 96.773, time 0.46
 * Upper 1 Val Acc 96.773, time 0.44
Task 1 average acc: 99.90543735224587
Task 2 average acc: 99.06953966699314
Task 3 average acc: 98.86825264256727
Task 4 average acc: 98.78630907826906
Task 5 average acc: 98.20419449266669
===Summary of experiment repeats: 6 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757 98.19222031 97.97734181 97.13446406 98.20419449
  0.          0.          0.          0.        ]
mean: 58.63146241288371 std: 47.87351133710638
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.495, Loss 0.021
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.45
Epoch:1
LR: 0.001
 * Train Acc 99.929, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.45
Epoch:2
LR: 0.001
 * Train Acc 99.929, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.49
Epoch:4
LR: 0.001
 * Train Acc 99.937, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.41
Epoch:5
LR: 0.001
 * Train Acc 99.929, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.49
Epoch:6
LR: 0.001
 * Train Acc 99.976, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.56
Epoch:7
LR: 0.001
 * Train Acc 99.953, Loss 0.001
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 99.953, time 0.41
Epoch:8
LR: 0.001
 * Train Acc 99.984, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.46
Epoch:9
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.44
Epoch:10
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.49
Epoch:11
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.49
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1320.2181396484375 -mean: 0.0032231886871159077 - std: 0.0003561234043445438
 * min 0.0017497156513854861, max: 0.0037047381047159433
sum: 703.8074340820312 -mean: 0.004398796241730452 - std: 0.00037988281110301614
 * min 0.0028070048429071903, max: 0.005423678085207939
sum: 5.879872798919678 - mean: 0.007349840831011534 - std: 0.0002535060921218246
 * min 0.006585273891687393, max: 0.00820861291140318
sum eps on layers: tensor([3.3005, 1.7595, 2.9399], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.44
 * Lower 1 Val Acc 99.953, time 0.37
 * Upper 1 Val Acc 99.953, time 0.61
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.218, Loss 0.172
 * , robust loss: 0.091 robust error: 0.04494382
 *  Val Acc 97.356, time 0.45
Epoch:1
LR: 0.001
 * Train Acc 96.931, Loss 0.063
 * , robust loss: 0.006 robust error: 0.00000000
 *  Val Acc 98.090, time 0.51
Epoch:2
LR: 0.001
 * Train Acc 97.262, Loss 0.046
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.041, time 0.42
Epoch:3
LR: 0.001
 * Train Acc 97.452, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.845, time 0.49
Epoch:4
LR: 0.001
 * Train Acc 97.419, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.286, time 0.44
Epoch:5
LR: 0.001
 * Train Acc 97.378, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.433, time 0.47
Epoch:6
LR: 0.001
 * Train Acc 97.452, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.041, time 0.43
Epoch:7
LR: 0.001
 * Train Acc 97.312, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.796, time 0.45
Epoch:8
LR: 0.001
 * Train Acc 97.312, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.405, time 0.46
Epoch:9
LR: 0.001
 * Train Acc 97.361, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.062, time 0.46
Epoch:10
LR: 0.001
 * Train Acc 97.270, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.649, time 0.41
Epoch:11
LR: 0.001
 * Train Acc 97.204, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.474, time 0.46
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1148.9930419921875 -mean: 0.002805158728733659 - std: 0.0009090927778743207
 * min 0.0006032005185261369, max: 0.004106367472559214
sum: 162.184326171875 -mean: 0.0010136519558727741 - std: 0.0002520892594475299
 * min 0.00035987343289889395, max: 0.001530299661681056
sum: 1.4441137313842773 - mean: 0.001805142150260508 - std: 0.00012460036668926477
 * min 0.0015159774338826537, max: 0.002147878520190716
sum eps on layers: tensor([2.8725, 0.4055, 0.7221], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.44
 * Lower 1 Val Acc 100.000, time 0.46
 * Upper 1 Val Acc 100.000, time 0.45
validation split name: 2
 *  Val Acc 96.474, time 0.49
 * Lower 1 Val Acc 90.548, time 0.39
 * Upper 1 Val Acc 90.548, time 0.43
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 91.201, Loss 0.285
 * , robust loss: 0.041 robust error: 0.01587302
 *  Val Acc 96.531, time 0.48
Epoch:1
LR: 0.001
 * Train Acc 97.114, Loss 0.084
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.599, time 0.45
Epoch:2
LR: 0.001
 * Train Acc 97.905, Loss 0.063
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.225, time 0.43
Epoch:3
LR: 0.001
 * Train Acc 98.180, Loss 0.053
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.919, time 0.53
Epoch:4
LR: 0.001
 * Train Acc 98.473, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.186, time 0.53
Epoch:5
LR: 0.001
 * Train Acc 98.500, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.399, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 98.624, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.972, time 0.42
Epoch:7
LR: 0.001
 * Train Acc 98.615, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.559, time 0.53
Epoch:8
LR: 0.001
 * Train Acc 98.491, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.48
Epoch:9
LR: 0.001
 * Train Acc 98.535, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.972, time 0.57
Epoch:10
LR: 0.001
 * Train Acc 98.562, Loss 0.041
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.43
Epoch:11
LR: 0.001
 * Train Acc 98.579, Loss 0.040
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.292, time 0.41
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1328.074462890625 -mean: 0.0032423692755401134 - std: 0.0012062325840815902
 * min 0.0005325507372617722, max: 0.004943919833749533
sum: 105.9212417602539 -mean: 0.000662007718347013 - std: 0.0001844649377744645
 * min 0.00019984893151558936, max: 0.001038666581735015
sum: 0.8300212621688843 - mean: 0.0010375265264883637 - std: 7.543613901361823e-05
 * min 0.0008840670925565064, max: 0.0012209828710183501
sum eps on layers: tensor([3.3202, 0.2648, 0.4150], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.46
 * Lower 1 Val Acc 100.000, time 0.43
 * Upper 1 Val Acc 100.000, time 0.45
validation split name: 2
 *  Val Acc 95.397, time 0.44
 * Lower 1 Val Acc 85.798, time 0.41
 * Upper 1 Val Acc 85.798, time 0.42
validation split name: 3
 *  Val Acc 98.292, time 0.41
 * Lower 1 Val Acc 95.678, time 0.48
 * Upper 1 Val Acc 95.678, time 0.42
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.197, Loss 0.233
 * , robust loss: 0.047 robust error: 0.00000000
 *  Val Acc 98.792, time 0.43
Epoch:1
LR: 0.001
 * Train Acc 99.114, Loss 0.049
 * , robust loss: 0.002 robust error: 0.00000000
 *  Val Acc 98.943, time 0.43
Epoch:2
LR: 0.001
 * Train Acc 99.483, Loss 0.029
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.345, time 0.39
Epoch:3
LR: 0.001
 * Train Acc 99.573, Loss 0.022
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.094, time 0.51
Epoch:4
LR: 0.001
 * Train Acc 99.590, Loss 0.018
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.245, time 0.42
Epoch:5
LR: 0.001
 * Train Acc 99.565, Loss 0.016
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.446, time 0.43
Epoch:6
LR: 0.001
 * Train Acc 99.606, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.446, time 0.42
Epoch:7
LR: 0.001
 * Train Acc 99.606, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.345, time 0.48
Epoch:8
LR: 0.001
 * Train Acc 99.639, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.396, time 0.50
Epoch:9
LR: 0.001
 * Train Acc 99.614, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.345, time 0.46
Epoch:10
LR: 0.001
 * Train Acc 99.655, Loss 0.012
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.295, time 0.37
Epoch:11
LR: 0.001
 * Train Acc 99.573, Loss 0.012
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.295, time 0.42
after batch eps: 1.500000000000037, kappa: 0.5
sum: 539.16552734375 -mean: 0.0013163220137357712 - std: 0.0005577796837314963
 * min 0.00015188285033218563, max: 0.0021202131174504757
sum: 24.600631713867188 -mean: 0.00015375395014416426 - std: 4.606452785083093e-05
 * min 4.168354644207284e-05, max: 0.00024714673054404557
sum: 0.18116936087608337 - mean: 0.00022646169236395508 - std: 2.0262883481336758e-05
 * min 0.00018432244542054832, max: 0.0002811408485285938
sum eps on layers: tensor([1.3479, 0.0615, 0.0906], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.43
 * Lower 1 Val Acc 100.000, time 0.51
 * Upper 1 Val Acc 100.000, time 0.49
validation split name: 2
 *  Val Acc 97.013, time 0.48
 * Lower 1 Val Acc 95.544, time 0.51
 * Upper 1 Val Acc 95.544, time 0.47
validation split name: 3
 *  Val Acc 95.358, time 0.44
 * Lower 1 Val Acc 93.970, time 0.41
 * Upper 1 Val Acc 93.970, time 0.45
validation split name: 4
 *  Val Acc 99.295, time 0.38
 * Lower 1 Val Acc 99.446, time 0.42
 * Upper 1 Val Acc 99.446, time 0.45
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 87.975, Loss 0.364
 * , robust loss: 0.158 robust error: 0.06000000
 *  Val Acc 92.738, time 0.47
Epoch:1
LR: 0.001
 * Train Acc 93.246, Loss 0.161
 * , robust loss: 0.025 robust error: 0.00000000
 *  Val Acc 93.949, time 0.47
Epoch:2
LR: 0.001
 * Train Acc 94.305, Loss 0.107
 * , robust loss: 0.025 robust error: 0.01000000
 *  Val Acc 94.049, time 0.49
Epoch:3
LR: 0.001
 * Train Acc 94.873, Loss 0.089
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 94.352, time 0.44
Epoch:4
LR: 0.001
 * Train Acc 95.178, Loss 0.081
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.108, time 0.44
Epoch:5
LR: 0.001
 * Train Acc 95.661, Loss 0.075
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.310, time 0.46
Epoch:6
LR: 0.001
 * Train Acc 95.831, Loss 0.072
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.562, time 0.50
Epoch:7
LR: 0.001
 * Train Acc 96.076, Loss 0.068
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.714, time 0.56
Epoch:8
LR: 0.001
 * Train Acc 96.127, Loss 0.066
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.764, time 0.55
Epoch:9
LR: 0.001
 * Train Acc 96.339, Loss 0.064
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.764, time 0.46
Epoch:10
LR: 0.001
 * Train Acc 96.407, Loss 0.062
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.016, time 0.49
Epoch:11
LR: 0.001
 * Train Acc 96.483, Loss 0.060
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.016, time 0.52
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 385.80206298828125 -mean: 0.0009418995468877256 - std: 0.0004896707832813263
 * min 4.214801811031066e-05, max: 0.001670519937761128
sum: 5.926311492919922 -mean: 3.7039444578113034e-05 - std: 1.2155806871305685e-05
 * min 7.827654371794779e-06, max: 6.275969644775614e-05
sum: 0.04135815054178238 - mean: 5.1697687013074756e-05 - std: 4.735728907689918e-06
 * min 4.132348112761974e-05, max: 6.547874363604933e-05
sum eps on layers: tensor([0.9645, 0.0148, 0.0207], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.45
 * Lower 1 Val Acc 100.000, time 0.49
 * Upper 1 Val Acc 100.000, time 0.47
validation split name: 2
 *  Val Acc 96.376, time 0.48
 * Lower 1 Val Acc 95.054, time 0.43
 * Upper 1 Val Acc 95.054, time 0.40
validation split name: 3
 *  Val Acc 96.638, time 0.51
 * Lower 1 Val Acc 95.731, time 0.44
 * Upper 1 Val Acc 95.731, time 0.40
validation split name: 4
 *  Val Acc 99.295, time 0.44
 * Lower 1 Val Acc 99.295, time 0.42
 * Upper 1 Val Acc 99.295, time 0.43
validation split name: 5
 *  Val Acc 96.016, time 0.50
 * Lower 1 Val Acc 95.915, time 0.47
 * Upper 1 Val Acc 95.915, time 0.47
Task 1 average acc: 100.0
Task 2 average acc: 98.23702252693437
Task 3 average acc: 97.89636418561332
Task 4 average acc: 97.91633052152437
Task 5 average acc: 97.665102305759
===Summary of experiment repeats: 7 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757 98.19222031 97.97734181 97.13446406 98.20419449
 97.66510231  0.          0.          0.        ]
mean: 68.39797264345961 std: 44.77818700574462
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.337, Loss 0.020
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.858, time 0.49
Epoch:1
LR: 0.001
 * Train Acc 99.913, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.50
Epoch:2
LR: 0.001
 * Train Acc 99.897, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.46
Epoch:3
LR: 0.001
 * Train Acc 99.937, Loss 0.001
 * , robust loss: 0.007 robust error: 0.00000000
 *  Val Acc 99.953, time 0.40
Epoch:4
LR: 0.001
 * Train Acc 99.937, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.46
Epoch:5
LR: 0.001
 * Train Acc 99.953, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.50
Epoch:6
LR: 0.001
 * Train Acc 99.976, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.45
Epoch:7
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.44
Epoch:8
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.48
Epoch:9
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.48
Epoch:10
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.43
Epoch:11
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.45
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1303.761474609375 -mean: 0.003183011431246996 - std: 0.00037737286766059697
 * min 0.0017314987489953637, max: 0.003675843821838498
sum: 691.3499755859375 -mean: 0.00432093720883131 - std: 0.0004160423413850367
 * min 0.002868911251425743, max: 0.005245818756520748
sum: 6.024442195892334 - mean: 0.007530552800744772 - std: 0.00028202010435052216
 * min 0.006716054864227772, max: 0.008461800403892994
sum eps on layers: tensor([3.2594, 1.7284, 3.0122], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.47
 * Lower 1 Val Acc 99.905, time 0.43
 * Upper 1 Val Acc 99.905, time 0.52
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 93.854, Loss 0.179
 * , robust loss: 0.066 robust error: 0.02247191
 *  Val Acc 97.111, time 0.48
Epoch:1
LR: 0.001
 * Train Acc 96.749, Loss 0.067
 * , robust loss: 0.008 robust error: 0.00000000
 *  Val Acc 97.747, time 0.40
Epoch:2
LR: 0.001
 * Train Acc 97.171, Loss 0.050
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 97.209, time 0.43
Epoch:3
LR: 0.001
 * Train Acc 97.088, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.160, time 0.45
Epoch:4
LR: 0.001
 * Train Acc 97.171, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.698, time 0.43
Epoch:5
LR: 0.001
 * Train Acc 97.287, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.335, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 97.295, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.992, time 0.46
Epoch:7
LR: 0.001
 * Train Acc 97.262, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.335, time 0.38
Epoch:8
LR: 0.001
 * Train Acc 97.386, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.894, time 0.41
Epoch:9
LR: 0.001
 * Train Acc 97.221, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.188, time 0.44
Epoch:10
LR: 0.001
 * Train Acc 97.105, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.845, time 0.46
Epoch:11
LR: 0.001
 * Train Acc 97.179, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.286, time 0.48
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1145.203125 -mean: 0.002795906038954854 - std: 0.0009120274917222559
 * min 0.0006266535492613912, max: 0.00404931977391243
sum: 154.87033081054688 -mean: 0.000967939558904618 - std: 0.00025406095664948225
 * min 0.00029439551872201264, max: 0.0014482521219179034
sum: 1.4996320009231567 - mean: 0.001874540001153946 - std: 0.00011612580419750884
 * min 0.001529492437839508, max: 0.002308323048055172
sum eps on layers: tensor([2.8630, 0.3872, 0.7498], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.46
 * Lower 1 Val Acc 99.905, time 0.47
 * Upper 1 Val Acc 99.905, time 0.47
validation split name: 2
 *  Val Acc 98.286, time 0.55
 * Lower 1 Val Acc 95.593, time 0.50
 * Upper 1 Val Acc 95.593, time 0.45
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 91.681, Loss 0.287
 * , robust loss: 0.014 robust error: 0.00000000
 *  Val Acc 96.852, time 0.41
Epoch:1
LR: 0.001
 * Train Acc 97.239, Loss 0.086
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.652, time 0.47
Epoch:2
LR: 0.001
 * Train Acc 97.851, Loss 0.065
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.118, time 0.43
Epoch:3
LR: 0.001
 * Train Acc 98.135, Loss 0.056
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.812, time 0.38
Epoch:4
LR: 0.001
 * Train Acc 98.269, Loss 0.051
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.026, time 0.45
Epoch:5
LR: 0.001
 * Train Acc 98.242, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.026, time 0.43
Epoch:6
LR: 0.001
 * Train Acc 98.278, Loss 0.048
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.866, time 0.45
Epoch:7
LR: 0.001
 * Train Acc 98.242, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.545, time 0.46
Epoch:8
LR: 0.001
 * Train Acc 97.985, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.279, time 0.45
Epoch:9
LR: 0.001
 * Train Acc 98.127, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.652, time 0.44
Epoch:10
LR: 0.001
 * Train Acc 97.985, Loss 0.050
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.225, time 0.40
Epoch:11
LR: 0.001
 * Train Acc 97.807, Loss 0.050
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.332, time 0.46
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1320.0064697265625 -mean: 0.0032226720359176397 - std: 0.001214667921885848
 * min 0.0005675403517670929, max: 0.004887890536338091
sum: 103.44017028808594 -mean: 0.0006465010228566825 - std: 0.00018855433154385537
 * min 0.00018138163432013243, max: 0.0010004433570429683
sum: 0.8827667236328125 - mean: 0.0011034583440050483 - std: 7.796323916409165e-05
 * min 0.0009145893855020404, max: 0.00134118867572397
sum eps on layers: tensor([3.3000, 0.2586, 0.4414], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.905, time 0.46
 * Lower 1 Val Acc 99.953, time 0.49
 * Upper 1 Val Acc 99.953, time 0.47
validation split name: 2
 *  Val Acc 98.188, time 0.41
 * Lower 1 Val Acc 94.319, time 0.41
 * Upper 1 Val Acc 94.319, time 0.54
validation split name: 3
 *  Val Acc 97.332, time 0.47
 * Lower 1 Val Acc 95.998, time 0.43
 * Upper 1 Val Acc 95.998, time 0.44
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.624, Loss 0.202
 * , robust loss: 0.032 robust error: 0.01204819
 *  Val Acc 98.590, time 0.44
Epoch:1
LR: 0.001
 * Train Acc 99.245, Loss 0.040
 * , robust loss: 0.003 robust error: 0.00000000
 *  Val Acc 98.892, time 0.45
Epoch:2
LR: 0.001
 * Train Acc 99.360, Loss 0.025
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.792, time 0.41
Epoch:3
LR: 0.001
 * Train Acc 99.442, Loss 0.020
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.043, time 0.37
Epoch:4
LR: 0.001
 * Train Acc 99.524, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.943, time 0.47
Epoch:5
LR: 0.001
 * Train Acc 99.516, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.943, time 0.50
Epoch:6
LR: 0.001
 * Train Acc 99.557, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.842, time 0.48
Epoch:7
LR: 0.001
 * Train Acc 99.524, Loss 0.013
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.993, time 0.43
Epoch:8
LR: 0.001
 * Train Acc 99.540, Loss 0.012
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.46
Epoch:9
LR: 0.001
 * Train Acc 99.573, Loss 0.012
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.245, time 0.50
Epoch:10
LR: 0.001
 * Train Acc 99.573, Loss 0.011
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.295, time 0.44
Epoch:11
LR: 0.001
 * Train Acc 99.508, Loss 0.011
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.295, time 0.40
after batch eps: 1.500000000000037, kappa: 0.5
sum: 533.0446166992188 -mean: 0.0013013784773647785 - std: 0.0005554775707423687
 * min 0.0001644838193897158, max: 0.00208973023109138
sum: 25.73047637939453 -mean: 0.00016081547073554248 - std: 4.978349170414731e-05
 * min 3.9886719605419785e-05, max: 0.0002585899201221764
sum: 0.20612439513206482 - mean: 0.00025765548343770206 - std: 2.1854797523701563e-05
 * min 0.00020706346549559385, max: 0.00032506685238331556
sum eps on layers: tensor([1.3326, 0.0643, 0.1031], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.47
 * Lower 1 Val Acc 99.953, time 0.49
 * Upper 1 Val Acc 99.953, time 0.42
validation split name: 2
 *  Val Acc 97.551, time 0.50
 * Lower 1 Val Acc 97.405, time 0.40
 * Upper 1 Val Acc 97.405, time 0.47
validation split name: 3
 *  Val Acc 97.118, time 0.46
 * Lower 1 Val Acc 96.958, time 0.40
 * Upper 1 Val Acc 96.958, time 0.37
validation split name: 4
 *  Val Acc 99.295, time 0.42
 * Lower 1 Val Acc 99.144, time 0.45
 * Upper 1 Val Acc 99.144, time 0.48
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 86.636, Loss 0.391
 * , robust loss: 0.134 robust error: 0.02000000
 *  Val Acc 91.982, time 0.40
Epoch:1
LR: 0.001
 * Train Acc 93.898, Loss 0.152
 * , robust loss: 0.016 robust error: 0.00000000
 *  Val Acc 95.159, time 0.47
Epoch:2
LR: 0.001
 * Train Acc 94.847, Loss 0.101
 * , robust loss: 0.005 robust error: 0.00000000
 *  Val Acc 95.310, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 95.492, Loss 0.084
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 95.562, time 0.43
Epoch:4
LR: 0.001
 * Train Acc 95.593, Loss 0.076
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.814, time 0.46
Epoch:5
LR: 0.001
 * Train Acc 95.924, Loss 0.071
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.117, time 0.46
Epoch:6
LR: 0.001
 * Train Acc 96.119, Loss 0.067
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.966, time 0.46
Epoch:7
LR: 0.001
 * Train Acc 96.186, Loss 0.064
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.369, time 0.43
Epoch:8
LR: 0.001
 * Train Acc 96.331, Loss 0.062
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.016, time 0.49
Epoch:9
LR: 0.001
 * Train Acc 96.398, Loss 0.060
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.520, time 0.49
Epoch:10
LR: 0.001
 * Train Acc 96.525, Loss 0.058
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.663, time 0.41
Epoch:11
LR: 0.001
 * Train Acc 96.602, Loss 0.057
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.218, time 0.53
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 384.18511962890625 -mean: 0.0009379519033245742 - std: 0.0004875267331954092
 * min 4.977320713805966e-05, max: 0.00164433300960809
sum: 6.321183681488037 -mean: 3.950739846914075e-05 - std: 1.3361516721488442e-05
 * min 7.989870937308297e-06, max: 6.673836469417438e-05
sum: 0.04746844992041588 - mean: 5.9335561672924086e-05 - std: 5.2344807954796124e-06
 * min 4.7361878387164325e-05, max: 7.548493158537894e-05
sum eps on layers: tensor([0.9605, 0.0158, 0.0237], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.49
 * Lower 1 Val Acc 99.953, time 0.47
 * Upper 1 Val Acc 99.953, time 0.42
validation split name: 2
 *  Val Acc 97.796, time 0.43
 * Lower 1 Val Acc 97.698, time 0.45
 * Upper 1 Val Acc 97.698, time 0.45
validation split name: 3
 *  Val Acc 97.225, time 0.46
 * Lower 1 Val Acc 97.492, time 0.45
 * Upper 1 Val Acc 97.492, time 0.46
validation split name: 4
 *  Val Acc 99.144, time 0.40
 * Lower 1 Val Acc 99.245, time 0.48
 * Upper 1 Val Acc 99.245, time 0.43
validation split name: 5
 *  Val Acc 96.218, time 0.40
 * Lower 1 Val Acc 96.621, time 0.41
 * Upper 1 Val Acc 96.621, time 0.42
Task 1 average acc: 99.90543735224587
Task 2 average acc: 99.09571573782715
Task 3 average acc: 98.475132878298
Task 4 average acc: 98.47941687274775
Task 5 average acc: 98.06720867944985
===Summary of experiment repeats: 8 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757 98.19222031 97.97734181 97.13446406 98.20419449
 97.66510231 98.06720868  0.          0.        ]
mean: 78.2046935114046 std: 39.10386614980716
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.226, Loss 0.025
 * , robust loss: 0.067 robust error: 0.01538462
 *  Val Acc 99.905, time 0.45
Epoch:1
LR: 0.001
 * Train Acc 99.921, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.50
Epoch:2
LR: 0.001
 * Train Acc 99.921, Loss 0.003
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.53
Epoch:3
LR: 0.001
 * Train Acc 99.953, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.50
Epoch:4
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.47
Epoch:5
LR: 0.001
 * Train Acc 99.984, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.44
Epoch:6
LR: 0.001
 * Train Acc 99.961, Loss 0.001
 * , robust loss: 0.020 robust error: 0.01538462
 *  Val Acc 100.000, time 0.47
Epoch:7
LR: 0.001
 * Train Acc 99.929, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.48
Epoch:8
LR: 0.001
 * Train Acc 99.937, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.51
Epoch:9
LR: 0.001
 * Train Acc 99.984, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.46
Epoch:10
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
Epoch:11
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 100.000, time 0.47
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1296.5455322265625 -mean: 0.003165394300594926 - std: 0.0003884300822392106
 * min 0.0015952516114339232, max: 0.0037210385780781507
sum: 657.6445922851562 -mean: 0.004110278561711311 - std: 0.0003949038218706846
 * min 0.0025088961701840162, max: 0.005037023685872555
sum: 6.229048728942871 - mean: 0.0077863107435405254 - std: 0.00038764855707995594
 * min 0.006774136330932379, max: 0.008979398757219315
sum eps on layers: tensor([3.2414, 1.6441, 3.1145], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.43
 * Lower 1 Val Acc 100.000, time 0.45
 * Upper 1 Val Acc 100.000, time 0.44
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 93.647, Loss 0.199
 * , robust loss: 0.058 robust error: 0.00000000
 *  Val Acc 96.964, time 0.47
Epoch:1
LR: 0.001
 * Train Acc 96.460, Loss 0.082
 * , robust loss: 0.011 robust error: 0.00000000
 *  Val Acc 96.670, time 0.45
Epoch:2
LR: 0.001
 * Train Acc 96.848, Loss 0.057
 * , robust loss: 0.002 robust error: 0.00000000
 *  Val Acc 97.307, time 0.46
Epoch:3
LR: 0.001
 * Train Acc 97.105, Loss 0.052
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.188, time 0.46
Epoch:4
LR: 0.001
 * Train Acc 97.254, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.894, time 0.45
Epoch:5
LR: 0.001
 * Train Acc 97.047, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.090, time 0.40
Epoch:6
LR: 0.001
 * Train Acc 97.171, Loss 0.048
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.866, time 0.50
Epoch:7
LR: 0.001
 * Train Acc 97.014, Loss 0.048
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.866, time 0.42
Epoch:8
LR: 0.001
 * Train Acc 97.088, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.405, time 0.43
Epoch:9
LR: 0.001
 * Train Acc 97.212, Loss 0.047
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.992, time 0.45
Epoch:10
LR: 0.001
 * Train Acc 96.633, Loss 0.052
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.258, time 0.42
Epoch:11
LR: 0.001
 * Train Acc 97.047, Loss 0.049
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.943, time 0.53
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1132.70751953125 -mean: 0.002765399171039462 - std: 0.000896755896974355
 * min 0.0005880881217308342, max: 0.00400918023660779
sum: 147.78640747070312 -mean: 0.0009236650075763464 - std: 0.00024142133770510554
 * min 0.00027331322780810297, max: 0.0013876623706892133
sum: 1.5975303649902344 - mean: 0.001996912993490696 - std: 0.000122408164315857
 * min 0.0016274877125397325, max: 0.0024649256374686956
sum eps on layers: tensor([2.8318, 0.3695, 0.7988], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.47
 * Lower 1 Val Acc 100.000, time 0.43
 * Upper 1 Val Acc 100.000, time 0.43
validation split name: 2
 *  Val Acc 97.943, time 0.43
 * Lower 1 Val Acc 98.041, time 0.46
 * Upper 1 Val Acc 98.041, time 0.44
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 91.903, Loss 0.285
 * , robust loss: 0.042 robust error: 0.00000000
 *  Val Acc 96.265, time 0.39
Epoch:1
LR: 0.001
 * Train Acc 96.866, Loss 0.088
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 97.972, time 0.50
Epoch:2
LR: 0.001
 * Train Acc 97.647, Loss 0.066
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.453, time 0.40
Epoch:3
LR: 0.001
 * Train Acc 98.002, Loss 0.056
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.399, time 0.46
Epoch:4
LR: 0.001
 * Train Acc 98.144, Loss 0.050
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.719, time 0.43
Epoch:5
LR: 0.001
 * Train Acc 98.233, Loss 0.046
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.666, time 0.46
Epoch:6
LR: 0.001
 * Train Acc 98.402, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.559, time 0.40
Epoch:7
LR: 0.001
 * Train Acc 98.331, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.879, time 0.42
Epoch:8
LR: 0.001
 * Train Acc 98.340, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.879, time 0.43
Epoch:9
LR: 0.001
 * Train Acc 98.366, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.506, time 0.41
Epoch:10
LR: 0.001
 * Train Acc 98.304, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.719, time 0.41
Epoch:11
LR: 0.001
 * Train Acc 98.251, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.453, time 0.47
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1307.2479248046875 -mean: 0.003191523253917694 - std: 0.0011853954056277871
 * min 0.0005126805626787245, max: 0.004865256138145924
sum: 100.36381530761719 -mean: 0.0006272738100960851 - std: 0.000180930903297849
 * min 0.00016384392802137882, max: 0.0009558855090290308
sum: 0.9619415998458862 - mean: 0.0012024269672110677 - std: 9.040826989803463e-05
 * min 0.0009810775518417358, max: 0.0014846405247226357
sum eps on layers: tensor([3.2681, 0.2509, 0.4810], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.41
 * Lower 1 Val Acc 100.000, time 0.47
 * Upper 1 Val Acc 100.000, time 0.45
validation split name: 2
 *  Val Acc 97.943, time 0.43
 * Lower 1 Val Acc 98.286, time 0.54
 * Upper 1 Val Acc 98.286, time 0.41
validation split name: 3
 *  Val Acc 98.453, time 0.38
 * Lower 1 Val Acc 98.239, time 0.39
 * Upper 1 Val Acc 98.239, time 0.40
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 93.696, Loss 0.253
 * , robust loss: 0.055 robust error: 0.00000000
 *  Val Acc 97.734, time 0.45
Epoch:1
LR: 0.001
 * Train Acc 98.851, Loss 0.058
 * , robust loss: 0.005 robust error: 0.00000000
 *  Val Acc 98.489, time 0.39
Epoch:2
LR: 0.001
 * Train Acc 99.031, Loss 0.035
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 98.691, time 0.39
Epoch:3
LR: 0.001
 * Train Acc 99.171, Loss 0.028
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.691, time 0.51
Epoch:4
LR: 0.001
 * Train Acc 99.311, Loss 0.024
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.943, time 0.46
Epoch:5
LR: 0.001
 * Train Acc 99.311, Loss 0.022
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.892, time 0.44
Epoch:6
LR: 0.001
 * Train Acc 99.393, Loss 0.020
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.42
Epoch:7
LR: 0.001
 * Train Acc 99.368, Loss 0.018
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.345, time 0.47
Epoch:8
LR: 0.001
 * Train Acc 99.458, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.43
Epoch:9
LR: 0.001
 * Train Acc 99.384, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.144, time 0.52
Epoch:10
LR: 0.001
 * Train Acc 99.401, Loss 0.016
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.691, time 0.49
Epoch:11
LR: 0.001
 * Train Acc 99.417, Loss 0.016
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.396, time 0.42
after batch eps: 1.500000000000037, kappa: 0.5
sum: 536.4122314453125 -mean: 0.001309600193053484 - std: 0.0005679402383975685
 * min 0.00013488531112670898, max: 0.002154485322535038
sum: 22.852874755859375 -mean: 0.00014283046766649932 - std: 4.41340816905722e-05
 * min 3.0293742383946665e-05, max: 0.0002265434741275385
sum: 0.2036745548248291 - mean: 0.00025459317839704454 - std: 2.2441781766247004e-05
 * min 0.00019966780382674187, max: 0.0003294061461929232
sum eps on layers: tensor([1.3410, 0.0571, 0.1018], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.45
 * Lower 1 Val Acc 100.000, time 0.43
 * Upper 1 Val Acc 100.000, time 0.48
validation split name: 2
 *  Val Acc 96.474, time 0.46
 * Lower 1 Val Acc 96.915, time 0.53
 * Upper 1 Val Acc 96.915, time 0.40
validation split name: 3
 *  Val Acc 97.439, time 0.39
 * Lower 1 Val Acc 98.026, time 0.41
 * Upper 1 Val Acc 98.026, time 0.40
validation split name: 4
 *  Val Acc 99.396, time 0.40
 * Lower 1 Val Acc 99.245, time 0.42
 * Upper 1 Val Acc 99.245, time 0.43
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 85.695, Loss 0.386
 * , robust loss: 0.186 robust error: 0.04000000
 *  Val Acc 91.982, time 0.41
Epoch:1
LR: 0.001
 * Train Acc 92.771, Loss 0.170
 * , robust loss: 0.030 robust error: 0.00000000
 *  Val Acc 93.142, time 0.42
Epoch:2
LR: 0.001
 * Train Acc 93.941, Loss 0.113
 * , robust loss: 0.008 robust error: 0.00000000
 *  Val Acc 94.302, time 0.42
Epoch:3
LR: 0.001
 * Train Acc 94.542, Loss 0.093
 * , robust loss: 0.002 robust error: 0.00000000
 *  Val Acc 94.352, time 0.52
Epoch:4
LR: 0.001
 * Train Acc 94.966, Loss 0.084
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 95.310, time 0.49
Epoch:5
LR: 0.001
 * Train Acc 95.237, Loss 0.079
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.260, time 0.49
Epoch:6
LR: 0.001
 * Train Acc 95.415, Loss 0.074
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.411, time 0.52
Epoch:7
LR: 0.001
 * Train Acc 95.712, Loss 0.071
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.209, time 0.48
Epoch:8
LR: 0.001
 * Train Acc 95.695, Loss 0.068
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.461, time 0.40
Epoch:9
LR: 0.001
 * Train Acc 95.924, Loss 0.066
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.562, time 0.51
Epoch:10
LR: 0.001
 * Train Acc 96.144, Loss 0.064
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.764, time 0.46
Epoch:11
LR: 0.001
 * Train Acc 96.186, Loss 0.063
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.966, time 0.46
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 385.0959167480469 -mean: 0.0009401755523867905 - std: 0.0004967536660842597
 * min 3.900426600011997e-05, max: 0.001690100645646453
sum: 5.563566207885742 -mean: 3.477228892734274e-05 - std: 1.1755760169762652e-05
 * min 5.826995675306534e-06, max: 5.7296922022942454e-05
sum: 0.046702660620212555 - mean: 5.8378325775265694e-05 - std: 5.207259619055549e-06
 * min 4.51246633019764e-05, max: 7.705824100412428e-05
sum eps on layers: tensor([0.9627, 0.0139, 0.0234], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 100.000, time 0.46
 * Lower 1 Val Acc 100.000, time 0.47
 * Upper 1 Val Acc 100.000, time 0.40
validation split name: 2
 *  Val Acc 96.033, time 0.45
 * Lower 1 Val Acc 95.690, time 0.51
 * Upper 1 Val Acc 95.690, time 0.41
validation split name: 3
 *  Val Acc 96.692, time 0.39
 * Lower 1 Val Acc 97.118, time 0.42
 * Upper 1 Val Acc 97.118, time 0.49
validation split name: 4
 *  Val Acc 99.295, time 0.48
 * Lower 1 Val Acc 99.194, time 0.46
 * Upper 1 Val Acc 99.194, time 0.44
validation split name: 5
 *  Val Acc 95.966, time 0.41
 * Lower 1 Val Acc 96.067, time 0.40
 * Upper 1 Val Acc 96.067, time 0.44
Task 1 average acc: 100.0
Task 2 average acc: 98.97159647404506
Task 3 average acc: 98.79856698411969
Task 4 average acc: 98.32711234617958
Task 5 average acc: 97.59712870059269
===Summary of experiment repeats: 9 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757 98.19222031 97.97734181 97.13446406 98.20419449
 97.66510231 98.06720868 97.5971287   0.        ]
mean: 87.96440638146387 std: 29.323533178855627
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
IntervalMLP(
  (fc1): LinearInterval(in_features=1024, out_features=400, bias=False)
  (fc2): LinearInterval(in_features=400, out_features=400, bias=False)
  (last): ModuleDict(
    (1): LinearInterval(in_features=400, out_features=2, bias=False)
    (2): LinearInterval(in_features=400, out_features=2, bias=False)
    (3): LinearInterval(in_features=400, out_features=2, bias=False)
    (4): LinearInterval(in_features=400, out_features=2, bias=False)
    (5): LinearInterval(in_features=400, out_features=2, bias=False)
  )
)
#parameter of model: 1147203
Task order: ['1', '2', '3', '4', '5']
====================== 1 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 99.226, Loss 0.020
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.574, time 0.46
Epoch:1
LR: 0.001
 * Train Acc 99.921, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.48
Epoch:2
LR: 0.001
 * Train Acc 99.937, Loss 0.002
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.858, time 0.46
Epoch:3
LR: 0.001
 * Train Acc 99.937, Loss 0.001
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 99.905, time 0.53
Epoch:4
LR: 0.001
 * Train Acc 99.976, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.905, time 0.57
Epoch:5
LR: 0.001
 * Train Acc 99.976, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 99.976, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.764, time 0.49
Epoch:7
LR: 0.001
 * Train Acc 99.953, Loss 0.001
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.858, time 0.43
Epoch:8
LR: 0.001
 * Train Acc 99.984, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.44
Epoch:9
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.42
Epoch:10
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.40
Epoch:11
LR: 0.001
 * Train Acc 100.000, Loss 0.000
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.953, time 0.43
after batch eps: 7.999999999999808, kappa: 0.5
sum: 1309.4072265625 -mean: 0.003196795005351305 - std: 0.00036458257818594575
 * min 0.0017641230951994658, max: 0.0036678242031484842
sum: 686.1577758789062 -mean: 0.0042884862050414085 - std: 0.00037199220969341695
 * min 0.002867978299036622, max: 0.005226465407758951
sum: 6.02217435836792 - mean: 0.0075277178548276424 - std: 0.00023314937425311655
 * min 0.0067584216594696045, max: 0.008405684493482113
sum eps on layers: tensor([3.2735, 1.7154, 3.0111], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.46
 * Lower 1 Val Acc 99.953, time 0.48
 * Upper 1 Val Acc 99.953, time 0.49
====================== 2 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.127, Loss 0.182
 * , robust loss: 0.058 robust error: 0.01123596
 *  Val Acc 97.405, time 0.48
Epoch:1
LR: 0.001
 * Train Acc 96.981, Loss 0.067
 * , robust loss: 0.003 robust error: 0.00000000
 *  Val Acc 98.090, time 0.44
Epoch:2
LR: 0.001
 * Train Acc 97.312, Loss 0.048
 * , robust loss: 0.005 robust error: 0.00000000
 *  Val Acc 96.572, time 0.45
Epoch:3
LR: 0.001
 * Train Acc 97.461, Loss 0.044
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.796, time 0.53
Epoch:4
LR: 0.001
 * Train Acc 97.452, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.580, time 0.51
Epoch:5
LR: 0.001
 * Train Acc 97.419, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.649, time 0.46
Epoch:6
LR: 0.001
 * Train Acc 97.568, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.580, time 0.44
Epoch:7
LR: 0.001
 * Train Acc 97.353, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.160, time 0.40
Epoch:8
LR: 0.001
 * Train Acc 97.320, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.992, time 0.45
Epoch:9
LR: 0.001
 * Train Acc 97.345, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.943, time 0.47
Epoch:10
LR: 0.001
 * Train Acc 97.461, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.286, time 0.42
Epoch:11
LR: 0.001
 * Train Acc 97.419, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.482, time 0.42
after batch eps: 3.999999999999917, kappa: 0.5
sum: 1137.823486328125 -mean: 0.002777889370918274 - std: 0.0009228142444044352
 * min 0.0006276735803112388, max: 0.004011926706880331
sum: 156.06716918945312 -mean: 0.0009754197672009468 - std: 0.00024903027224354446
 * min 0.00031676117214374244, max: 0.0014694039709866047
sum: 1.5305464267730713 - mean: 0.0019131830194965005 - std: 0.00012039426655974239
 * min 0.0015438614645972848, max: 0.0023921742103993893
sum eps on layers: tensor([2.8446, 0.3902, 0.7653], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.43
 * Lower 1 Val Acc 99.953, time 0.42
 * Upper 1 Val Acc 99.953, time 0.47
validation split name: 2
 *  Val Acc 98.482, time 0.42
 * Lower 1 Val Acc 98.188, time 0.46
 * Upper 1 Val Acc 98.188, time 0.40
====================== 3 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 92.071, Loss 0.266
 * , robust loss: 0.022 robust error: 0.00000000
 *  Val Acc 96.852, time 0.42
Epoch:1
LR: 0.001
 * Train Acc 97.576, Loss 0.079
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.172, time 0.40
Epoch:2
LR: 0.001
 * Train Acc 98.100, Loss 0.059
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.506, time 0.45
Epoch:3
LR: 0.001
 * Train Acc 98.278, Loss 0.051
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.346, time 0.41
Epoch:4
LR: 0.001
 * Train Acc 98.473, Loss 0.046
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.453, time 0.46
Epoch:5
LR: 0.001
 * Train Acc 98.446, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.666, time 0.43
Epoch:6
LR: 0.001
 * Train Acc 98.491, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.132, time 0.42
Epoch:7
LR: 0.001
 * Train Acc 98.366, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.759, time 0.39
Epoch:8
LR: 0.001
 * Train Acc 98.464, Loss 0.042
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 98.186, time 0.47
Epoch:9
LR: 0.001
 * Train Acc 98.162, Loss 0.043
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.332, time 0.43
Epoch:10
LR: 0.001
 * Train Acc 98.056, Loss 0.045
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.599, time 0.44
Epoch:11
LR: 0.001
 * Train Acc 97.842, Loss 0.046
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 97.599, time 0.40
after batch eps: 3.9999999999999347, kappa: 0.5
sum: 1313.60546875 -mean: 0.003207044443115592 - std: 0.0012151417322456837
 * min 0.0005534496740438044, max: 0.004855907056480646
sum: 105.46974182128906 -mean: 0.000659185869153589 - std: 0.00018714851466938853
 * min 0.00018710856966208667, max: 0.0010497684124857187
sum: 0.9046233892440796 - mean: 0.0011307791573926806 - std: 7.848659879527986e-05
 * min 0.0009486155468039215, max: 0.001356482389383018
sum eps on layers: tensor([3.2840, 0.2637, 0.4523], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.47
 * Lower 1 Val Acc 99.953, time 0.45
 * Upper 1 Val Acc 99.953, time 0.43
validation split name: 2
 *  Val Acc 98.384, time 0.41
 * Lower 1 Val Acc 98.090, time 0.43
 * Upper 1 Val Acc 98.090, time 0.43
validation split name: 3
 *  Val Acc 97.599, time 0.43
 * Lower 1 Val Acc 87.407, time 0.43
 * Upper 1 Val Acc 87.407, time 0.40
====================== 4 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 94.172, Loss 0.244
 * , robust loss: 0.050 robust error: 0.00000000
 *  Val Acc 98.590, time 0.49
Epoch:1
LR: 0.001
 * Train Acc 98.990, Loss 0.054
 * , robust loss: 0.005 robust error: 0.00000000
 *  Val Acc 98.842, time 0.41
Epoch:2
LR: 0.001
 * Train Acc 99.343, Loss 0.032
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.194, time 0.44
Epoch:3
LR: 0.001
 * Train Acc 99.393, Loss 0.025
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.345, time 0.49
Epoch:4
LR: 0.001
 * Train Acc 99.532, Loss 0.021
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.547, time 0.47
Epoch:5
LR: 0.001
 * Train Acc 99.581, Loss 0.018
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.547, time 0.48
Epoch:6
LR: 0.001
 * Train Acc 99.557, Loss 0.017
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.547, time 0.41
Epoch:7
LR: 0.001
 * Train Acc 99.549, Loss 0.016
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.446, time 0.43
Epoch:8
LR: 0.001
 * Train Acc 99.614, Loss 0.015
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.496, time 0.44
Epoch:9
LR: 0.001
 * Train Acc 99.639, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.245, time 0.42
Epoch:10
LR: 0.001
 * Train Acc 99.631, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.547, time 0.39
Epoch:11
LR: 0.001
 * Train Acc 99.581, Loss 0.014
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 99.597, time 0.43
after batch eps: 1.500000000000037, kappa: 0.5
sum: 538.3638916015625 -mean: 0.0013143649557605386 - std: 0.0005818732315674424
 * min 0.0001449088449589908, max: 0.002140743425115943
sum: 23.74826431274414 -mean: 0.00014842665405012667 - std: 4.5562683226307854e-05
 * min 3.426076000323519e-05, max: 0.00024257109907921404
sum: 0.189439058303833 - mean: 0.00023679881996940821 - std: 1.9882565538864583e-05
 * min 0.00019075909222010523, max: 0.0002973647788167
sum eps on layers: tensor([1.3459, 0.0594, 0.0947], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.40
 * Lower 1 Val Acc 99.953, time 0.42
 * Upper 1 Val Acc 99.953, time 0.39
validation split name: 2
 *  Val Acc 96.376, time 0.41
 * Lower 1 Val Acc 95.739, time 0.42
 * Upper 1 Val Acc 95.739, time 0.44
validation split name: 3
 *  Val Acc 95.144, time 0.39
 * Lower 1 Val Acc 97.172, time 0.42
 * Upper 1 Val Acc 97.172, time 0.44
validation split name: 4
 *  Val Acc 99.597, time 0.44
 * Lower 1 Val Acc 99.446, time 0.49
 * Upper 1 Val Acc 99.446, time 0.41
====================== 5 =======================
before batch eps: 0, kappa: 1
Epoch:0
LR: 0.001
 * Train Acc 85.339, Loss 0.388
 * , robust loss: 0.152 robust error: 0.03000000
 *  Val Acc 92.385, time 0.40
Epoch:1
LR: 0.001
 * Train Acc 92.771, Loss 0.161
 * , robust loss: 0.027 robust error: 0.00000000
 *  Val Acc 94.150, time 0.44
Epoch:2
LR: 0.001
 * Train Acc 94.102, Loss 0.107
 * , robust loss: 0.015 robust error: 0.01000000
 *  Val Acc 94.604, time 0.42
Epoch:3
LR: 0.001
 * Train Acc 94.686, Loss 0.090
 * , robust loss: 0.001 robust error: 0.00000000
 *  Val Acc 95.512, time 0.47
Epoch:4
LR: 0.001
 * Train Acc 95.178, Loss 0.081
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.411, time 0.47
Epoch:5
LR: 0.001
 * Train Acc 95.525, Loss 0.075
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.411, time 0.45
Epoch:6
LR: 0.001
 * Train Acc 95.754, Loss 0.071
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.613, time 0.45
Epoch:7
LR: 0.001
 * Train Acc 96.085, Loss 0.067
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.966, time 0.41
Epoch:8
LR: 0.001
 * Train Acc 96.119, Loss 0.064
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 96.016, time 0.43
Epoch:9
LR: 0.001
 * Train Acc 96.339, Loss 0.062
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.865, time 0.48
Epoch:10
LR: 0.001
 * Train Acc 96.398, Loss 0.060
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.966, time 0.48
Epoch:11
LR: 0.001
 * Train Acc 96.500, Loss 0.059
 * , robust loss: 0.000 robust error: 0.00000000
 *  Val Acc 95.613, time 0.41
after batch eps: 1.0000000000000182, kappa: 0.5
sum: 385.359375 -mean: 0.0009408187470398843 - std: 0.0005066455923952162
 * min 4.165328937233426e-05, max: 0.0016731171635910869
sum: 5.86245584487915 -mean: 3.664034738903865e-05 - std: 1.2281141607672907e-05
 * min 6.992882390477462e-06, max: 6.271317397477105e-05
sum: 0.04389072582125664 - mean: 5.4863405239302665e-05 - std: 5.135511401022086e-06
 * min 4.231115599395707e-05, max: 7.269897469086573e-05
sum eps on layers: tensor([0.9634, 0.0147, 0.0219], device='cuda:0', grad_fn=<DivBackward0>)
validation split name: 1
 *  Val Acc 99.953, time 0.46
 * Lower 1 Val Acc 99.953, time 0.44
 * Upper 1 Val Acc 99.953, time 0.43
validation split name: 2
 *  Val Acc 96.033, time 0.45
 * Lower 1 Val Acc 95.446, time 0.40
 * Upper 1 Val Acc 95.446, time 0.47
validation split name: 3
 *  Val Acc 94.931, time 0.40
 * Lower 1 Val Acc 96.585, time 0.38
 * Upper 1 Val Acc 96.585, time 0.41
validation split name: 4
 *  Val Acc 99.396, time 0.48
 * Lower 1 Val Acc 99.496, time 0.41
 * Upper 1 Val Acc 99.496, time 0.43
validation split name: 5
 *  Val Acc 95.613, time 0.42
 * Lower 1 Val Acc 96.369, time 0.41
 * Upper 1 Val Acc 96.369, time 0.43
Task 1 average acc: 99.95271867612293
Task 2 average acc: 99.21729959271377
Task 3 average acc: 98.6451251031495
Task 4 average acc: 97.76751940996456
Task 5 average acc: 97.18502548835714
===Summary of experiment repeats: 10 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [97.46544589 97.34095757 98.19222031 97.97734181 97.13446406 98.20419449
 97.66510231 98.06720868 97.5971287  97.18502549]
mean: 97.68290893029959 std: 0.3854983357020579
reg_coef: 0.0 mean: 97.68290893029959 std: 0.3854983357020579
* kappa decrease from 1 to 0.5 in [1.0, 1.0, 1.0, 1.0, 1.0] epoch
* eps increase by [8.0, 4.0, 4.0, 1.5, 1.0] every [12.0, 12.0, 12.0, 12.0, 12.0] epoch
* maximal eps: [0.0, 0.0, 0.0, 0.0, 0.0]
* tasks were trained [12, 12, 12, 12, 12] epoch with clipping
